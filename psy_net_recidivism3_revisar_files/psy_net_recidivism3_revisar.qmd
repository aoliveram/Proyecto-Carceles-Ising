---
title: "Recidivism from a network psychometric perspective"
format: docx
editor: visual
---

## Análisis de la base de datos integrada

En la base de datos integrada (ruta: D:/varios/Fondecyt_carceles/internos/pape/ising/base_integrada.csv) tenemos las primeras aplicaciones del IGI en una muestra de internos desde el 2015, la fecha en que reingresaron a la cárcel (si es que lo hicieron) y diversos atributos individuales como género, sexo, nivel de educación, existencia de problemas mentales, etc.

Lo que corresponde ahora es analizar el IGI en ellos, primero de la forma tradicional, luego usando psicometría de redes.

```{r setup,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
#rm(list=ls())
#library(here)

#aqui <- here()

#base_igi <- read.csv(paste0(aqui, "/pape/ising/base_psy_net_recidivism.csv"))
```


```{r transformaciones_atributos,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# Importamos
base_igi <- read.csv("base_psy_net_recidivism.csv")

# Convertimos la variable EDAD a factor para manejar valores como "S.I."
base_igi$EDAD <- as.factor(base_igi$EDAD)

# Creamos la variable 'rangos_edad' agrupando las edades en las categorías deseadas
base_igi$rangos_edad <- dplyr::case_when(
  as.numeric(as.character(base_igi$EDAD)) < 25 ~ "Menores de 25",
  as.numeric(as.character(base_igi$EDAD)) >= 25 & as.numeric(as.character(base_igi$EDAD)) <= 39 ~ "Entre 25 y 39",
  as.numeric(as.character(base_igi$EDAD)) >= 40 ~ "40 o más",
  TRUE ~ "Sin información"
)

# Convertimos la nueva variable en factor para facilitar el análisis posterior
base_igi$rangos_edad <- factor(base_igi$rangos_edad, 
                               levels = c("Menores de 25", "Entre 25 y 39", "40 o más", "Sin información"))


base_igi$elim_edad <- ifelse(base_igi$EDAD == "S.I.", "Sin información", "Con información")
sin_info_edad <- row.names(base_igi[base_igi$elim_edad == "Sin información", ])


base_igi$recod_estado_civil <- dplyr::case_when(
  base_igi$ESTADO_CIVIL %in% c("CASADO", "CONVIVIENTE CIVIL") ~ "Con pareja",
  base_igi$ESTADO_CIVIL %in% c("SEPARADO/DIVORCIADO", "VIUDO", "SOLTERO") ~ "Sin pareja",
  TRUE ~ NA_character_
)

base_igi$recod_estado_civil <- factor(base_igi$recod_estado_civil, levels = c("Con pareja", "Sin pareja"))


```

## Explorando la bbdd IGI

Algunas tablas descriptivas de la base: EDAD

```{r tablas, echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# Verificamos la distribución de la nueva variable
table(base_igi$rangos_edad)
table(base_igi$recod_estado_civil)
table(base_igi$SEXO)
table(base_igi$COD_SALUD_MENTAL)

```

En este ejercicio, revisamos la base de datos de aplicaciones del IGI a internos entregados por Gendarmería para el desarrollo del proyecto Fondecyt. Las preguntas principales que queremos responder son:

¿Cómo contribuyen cada una de las variables al riesgo total que tiene un interno?

¿Hay variables que muestran los mismos patrones tal que se puede decir que la presencia/ausencia de una es coocurrente con la presencia/ausencia de otra para distintos perfiles de riesgo?

¿Hay diferencias en cómo se relacionan los distintos componentes del IGI para personas con distintas características, por ejemplo, entre personas con y sin enfermedades mentales?

¿Hay diferencias en capacidad predictiva de la reincidencia para personas con igual riesgo según IGI tras considerar inputs de redes psicométricas?

```{r paquetes, echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# algunos paquetes que iremos usando. Ojo después con paquetes de redes que suelen tener funciones diferentes con el mismo nombre

#library(here)
library(readxl)
library(EGAnet)
library(dplyr)
library(stringr)
library(car)
library(psychonetrics)
library(cooccur)
library(visNetwork)
library(igraph)
library(ggplot2)
```

```{r bases, echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# limpiamos la base y eliminamos las variables resumen de cada modulo

base_igi$X.8. <- car::recode(base_igi$X.8.,"2=NA")
base_igi$X.17. <- car::recode(base_igi$X.17.,"4=NA")
base_igi$X.21. <- car::recode(base_igi$X.21.,"2=NA")
base_igi$X.23. <- car::recode(base_igi$X.23.,"4=NA")
base_igi$X.27. <- car::recode(base_igi$X.27.,"4=NA")
base_igi$X.35. <- car::recode(base_igi$X.35.,"2=NA")
base_igi$X.39. <- car::recode(base_igi$X.39.,"2=NA")

eliminar <- c("X.42.", "X.43.", "X.44.", "X.45.", "X.47.", "X.48.", "X.49." ,
"X.51.", "X.52.", "X.53.", "X.54.", "X.55.", "X.56.", "X.57.", "X.58.") # se eliminan porque son subitems, por ejemplo
# 42, 43, 44 y 45 son subítems de 41; 47, 48 y 49 lo son de 46, etc.

base_igi <- base_igi[,!(colnames(base_igi) %in% eliminar)]

descriptivo_grupal <- c("HD1","HD2","HD3","HD4","HD5","HD6","HD7","HD8",
                        "EDU9","EDU10","EDU11","EDU12","EDU13","EDU14","EDU15","EDU16","EDU17",
                        "FAM18","FAM19","FAM20","FAM21",
                        "UTL22","UTL23",
                        "PAR24","PAR25","PAR26","PAR27",
                        "CAD28","CAD29","CAD30","CAD31","CAD32","CAD33","CAD34","CAD35",
                        "PRO36","PRO37","PRO38","PRO39",
                        "PAT40","PAT41","PAT42","PAT43")

colnames(base_igi)[8:50] <- descriptivo_grupal

descriptivo <- c("1.Sanciones como menor de edad o condenas previas",
                 "2.Dos o más condenas previas",
                 "3.Tres o más condenas previas",
                 "4.Cumple condena por 3+ delitos",
                 "5.Imputado por delito antes de los 18",
                 "6.Cumplido condena privado de libertad",
                 "7.Castigado mientras cumplia condena en cárcel",
                 "8.Formalizado mientras estaba en la cárcel",
                 "9.Actualmente desempleado",
                 "10.Frecuentemente desempleado",
                 "11.Nunca ha mantenido empleo por año completo",
                 "12.Educación básica incompleta",
                 "13.Educación media incompleta",
                 "14.Suspendido/Expulsado de colegio al menos 1 vez",
                 "15.Participación/Desempeño",
                 "16.Interacción con pares",
                 "17.Interacción con autoridad",
                 "18.Insatisfacción vida en pareja",
                 "19.Mala relación con los padres",
                 "20.Mala relación con otros familiares",
                 "21.Familiares/Pareja con antecedentes",
                 "22.Participacion reciente en actividad comunitaria",
                 "23.Uso de tiempo libre",
                 "24.Tiene conocidos infractores",
                 "25.Amigos infractores",
                 "26.Tiene pocos conocidos prosiciales",
                 "27.Pocos amigos prosociales",
                 "28.Consumo problemático de alcohol",
                 "29.Consumo problemático de drogas",
                 "30.Problemas actuales con alcohol",
                 "31.Problemas actuales con drogas",
                 "32.Infracciones de ley",
                 "33.Pareja/familia",
                 "34.Colegio/Trabajo",
                 "35.Indicaciones médicas",
                 "36.Tendencia a favor del delito",
                 "37.Actitud desfavorable ante normas",
                 "38. Actitud desfavorable ante las condenas",
                 "39. Actitud desfavorable hacia autoridad",
                 "40. Existe patrón antisocial",
                 "41. Conducta antisocial precoz y diversa",
                 "42. Actitudes delictuales",
                 "43. Estilo de vida disfuncional")

```

Las variables del IGI y su etiqueta son:

```{r var, echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
descriptivo_grupal

descriptivo
```

Los valores de cada pregunta del IGI se suman para obtener el nivel de riesgo que se asociada a cada interno. Algunas tienen dos valores, otras tres y otras cuatro valores. En algunas variables los valores van de 0 a 3, donde los casos 2 y 3 son de menor riesgo y no requieren intervención y los casos 0 y 1 son de más riesgo y si requieren intervención. Dicotomizamos cada variable para que el foco sea: no-intervención, intervención. Además, recodificamos para que todos los puntajes estén alineados de forma tal que sumar más puntos impliquen más riesgo.

```{r recodificacion_IGI, echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# binarizamos las variables que tienen cuatro valores. El principio rector será "0 = no necesidad de intervención" y "1 = Necesidad de intervención"

recode_variables_ptje <- function(x) {
  # Variables a recodificar
  vars_to_recode <- c("EDU15", "EDU16", "EDU17", "FAM18", "FAM19", "FAM20", 
                      "UTL23", "PAR25", "PAR27", "CAD30", "CAD31", 
                      "PRO36", "PRO37")

  # Verificamos que las variables existan en el data frame
  missing_vars <- setdiff(vars_to_recode, names(x))
  if (length(missing_vars) > 0) {
    warning("Las siguientes variables no existen en el data frame: ", paste(missing_vars, collapse = ", "))
  }
  
  for (col in vars_to_recode) {
    if (col %in% names(x)) {
      x[[col]] <- ifelse(x[[col]] == 4, NA, 
                         ifelse(x[[col]] %in% c(3), 0,
                                ifelse(x[[col]] %in% c(2), 0,
                                       ifelse(x[[col]] %in% c(1), 1,
                                       1))))
    }
  }
  
  return(x)
}

base_igi <- base_igi %>%
  filter(across(all_of(descriptivo_grupal), ~ !is.na(.)))

```

El siguiente gráfico muestra la distribución de los puntajes totales obtenidos en la muestra.

```{r base_ptje, echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
base_ptje <- recode_variables_ptje(base_igi)

# Función para sumar los valores por fila de las variables en descriptivo_grupal
sumar_por_fila <- function(base, variables) {
  # Verificar si las variables están en la base de datos
  variables_presentes <- variables %in% colnames(base)
  if (!all(variables_presentes)) {
    stop("Algunas variables en 'descriptivo_grupal' no están presentes en la base de datos.")
  }
  
  # Seleccionamos las columnas correspondientes y sumamos por fila
  fila_sumas <- rowSums(base[ , variables], na.rm = TRUE)
  
  return(fila_sumas)
}

puntaje_total <- sumar_por_fila(base_ptje, descriptivo_grupal)

base_ptje$puntaje_total <- puntaje_total
base_igi$puntaje_total <- puntaje_total

des <- summary(puntaje_total)
mediana <- median(puntaje_total)
desv <- sd(puntaje_total)
hist(puntaje_total,
     main = "Distribución de puntajes en el IGI",
     ylab = "Número de casos",
     xlab = "Puntage total IGI",
     col = "gold")

```

Con lo anterior, podemos crear el siguiente heatmap que permite comparar a todas las variables para todos los puntajes totales. De forma tal de saber para cada item/pregunta del IGI se ve la proporción de respuestas en que si está o no está activo cuando se da ese puntaje.

```{r heatmap1, echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# Lo primero que vamos a hacer es ver qué atributos se "activan" para cada posible  puntaje. Es decir, si alguien tiene 10 puntos, se activarán el atributo X, Y, Z,... si a todos los que tienen 10 puntos se les activan los mismos atributos, entonees, esas variables estarán activa el 100% de las veces en las personas con 10 puntos. Si no es así, será en la proporción respectiva respecto del total de personas con 10 puntos. A partir de esto, podemos generar un heatmap que resuma todas las proporciones de todos los atributos para todos los puntajes.

base_ptje <- base_ptje[is.na(base_ptje$puntaje_total)==F,]

valores_puntaje <- unique(puntaje_total)
valores_puntaje <-  sort(valores_puntaje, decreasing = F) 

base_proporciones <- matrix(0, nrow = length(descriptivo_grupal), ncol = length(valores_puntaje))
base_proporciones <- as.data.frame(base_proporciones)
colnames(base_proporciones) <- valores_puntaje
row.names(base_proporciones) <- descriptivo_grupal

# Calculamos una sola vez los casos filtrados para cada j
for (j in 1:length(valores_puntaje)) {
    casos_filtrados <- base_ptje[base_ptje$puntaje_total == valores_puntaje[j], ]
    casos_filtrados <- casos_filtrados[,colnames(casos_filtrados) %in% descriptivo_grupal]
    total_casos_para_j <- nrow(casos_filtrados)  # El número de casos para el puntaje j

    if (total_casos_para_j > 0) {  # Para evitar división por cero
        for (i in 1:43) {
            # Contar cuántas veces la variable i tiene valor 1 en esos casos filtrados
          z <- sum(casos_filtrados[, i]) / total_casos_para_j
          ifelse(z != "NA",
                 base_proporciones[i, which(valores_puntaje == j)] <- sum(casos_filtrados[, i]) / total_casos_para_j,
                 base_proporciones[i, which(valores_puntaje == j)] <- 0)
        }
    }
}

# Convertimos la matriz a un formato adecuado para ggplot2
base_proporciones_df <- as.data.frame(as.table(as.matrix(base_proporciones)))

# Renombramos las columnas para mayor claridad
names(base_proporciones_df) <- c("Variable", "PuntajeTotal", "Frecuencia")

# Calculamos la media de las proporciones para cada fila
base_proporciones$MediaProporciones <- rowMeans(base_proporciones)

# Creamos una columna con la categoría (PAT, PAR, CAD..., según corresponda) basada en los nombres de las filas
base_proporciones$Categoria <- gsub("[^A-Za-z]+", "", rownames(base_proporciones))

# Ordenamos dentro de cada categoría por la media de proporciones
base_proporciones <- base_proporciones[order(base_proporciones$Categoria, -base_proporciones$MediaProporciones), ]

# Identificamos posiciones donde cambian las categorías
category_breaks <- cumsum(table(base_proporciones$Categoria))

# Reconstruimos el dataframe para ggplot2 después de ordenar
# base_proporciones_df <- as.data.frame(as.table(as.matrix(base_proporciones[ , -ncol(base_proporciones)])))
base_proporciones_df <- as.data.frame(as.table(as.matrix(base_proporciones[, !(colnames(base_proporciones) %in% c("MediaProporciones", "Categoria"))])))

names(base_proporciones_df) <- c("Variable", "PuntajeTotal", "Frecuencia")


# Creamos el mapa de calor con líneas grises entre categorías
ggplot(base_proporciones_df, aes(x = PuntajeTotal, y = Variable, fill = Frecuencia)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(title = "Proporción de activación de ítems segun puntaje total", 
       x = "Puntaje Total", 
       y = "Variable", 
       fill = "Proporción") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_hline(yintercept = category_breaks + 0.5, color = "gold", size = 0.5, linetype = "dashed")  # Líneas grises separando categorías

```

Como puede observarse en el mapa de calor, algunas variables tienen presencia en prácticamente todos los puntajes o en una gran parte de ellos. Por ejemplo, las variables HD6 y PAR24 están presentes en casi todas las categorías, mientras que otras, como la variable CAD35, solo aparecen hacia el final, en las categorías más altas de riesgo. Algo similar ocurre con la variable UTL22, que está presente únicamente en las categorías iniciales de puntajes bajos y luego reaparece en puntajes elevados, como en la categoría PAR25.

Este análisis pone en evidencia patrones y posibles diferencias relevantes entre niveles de puntaje, mostrando cómo están relacionadas las variables, lo cual anticipa que podría ser valioso un análisis de las estructuras o combinaciones de variables que se activan para cada nivel de riesgo a la hora de interpretar las dinámicas subyacentes en los datos y su potencial vinculación con patrones de reincidencia. Veamos eso más adelante. Antes de ir en esa dirección veamos cómo se relaciona el puntaje de riesgo con los niveles de reincidencia.

## Puntaje total y reincidencia

Si el IGI sirve para el propósito inicial para el que fue hecho de medir riesgo de reincidencia, debería producirse que la distribución de puntajes de personas que reincidieron está más a la derecha que la distribución de personas que no reincidieron.

```{r ptj_y_reincidencia, echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# Se supone que los puntajes del IGI son indicativos de nivel de riesgo (mayor puntaje más riesgo). Por ende, verifiquemos si los datos muestran eso, separando los puntajes por rangos de riesgo y conectándolos con el dato de reincidencia posterior que tenemos de cada individuo.

base_igi$reincidencia <- ifelse(is.na(base_igi$FECHA_REINGRESO)==T,0,1)



# Creamos la nueva variable categórica en base a los tramos definidos
base_igi$riesgo_cat <- cut(
  base_igi$puntaje_total,
  breaks = c(-Inf, 4, 10, 19, 29, Inf),  # Límites de los tramos
  labels = c("Muy bajo", "Bajo", "Medio", "Alto", "Muy alto"),  # Categorías
  right = TRUE  # Incluir el límite superior en cada intervalo
)

base_igi$riesgo <- cut(
  base_igi$puntaje_total,
  breaks = c(-Inf, 4, 10, 19, 29, Inf),  # Límites de los tramos
  labels = c(1,2,3,4,5),  # Categorías
  right = TRUE  # Incluir el límite superior en cada intervalo
)

base_igi$riesgo <- as.numeric(base_igi$riesgo)

tabla_frecuencias <- table(base_igi$riesgo, base_igi$reincidencia)
tabla_proporciones <- prop.table(tabla_frecuencias, margin = 2)
tabla_proporciones <- as.data.frame(tabla_proporciones)

tabla_proporciones$Var1 <- as.numeric(as.character(tabla_proporciones$Var1))

# Generamos el gráfico base para Var2 == 0
plot(
  tabla_proporciones$Var1[tabla_proporciones$Var2 == 0], 
  tabla_proporciones$Freq[tabla_proporciones$Var2 == 0], 
  type = "o", col = "blue", xlab = "Riesgo", ylab = "Proporción", 
  ylim = c(0, max(tabla_proporciones$Freq)), 
  main = "Proporciones por Riesgo y Reincidencia", xaxt = "n"
)

# Añadimos el eje X con etiquetas personalizadas
axis(1, at = tabla_proporciones$Var1[tabla_proporciones$Var2 == 0], 
     labels = c("Muy bajo", "Bajo", "Medio", "Alto", "Muy alto"))

# Añadimos la línea para Var2 == 1
lines(
  tabla_proporciones$Var1[tabla_proporciones$Var2 == 1], 
  tabla_proporciones$Freq[tabla_proporciones$Var2 == 1], 
  type = "o", col = "red"
)

# Agregamos una leyenda
legend("topleft", legend = c("Reincidencia = 0", "Reincidencia = 1"),
       col = c("blue", "red"), lty = 1, pch = 1)

# Agregamos una cuadrícula
grid()


```

Como puede verse, hay una relación entre reincidencia y el puntaje del IGI. Es mayor la proporción de casos con reincidencia en valores de riesgo altos y menor en valores de riesgo bajo. La correlación entre ambas variables es de `r round(cor(base_igi$puntaje_total,base_igi$reincidencia),2)`.

Volvamos entonces a la consideración de variables que aparecen juntas más recurrentemente a distintos niveles de riesgo.

```{r heatmap2, echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

base_proporciones_df <- as.data.frame(as.table(as.matrix(base_proporciones[, !(colnames(base_proporciones) %in% c("MediaProporciones", "Categoria"))])))
names(base_proporciones_df) <- c("Variable", "PuntajeTotal", "Frecuencia")

# Ordenamos todas las variables por la media de proporciones (sin agrupar por categorías)
risk_category_breaks <- c(-Inf, 4, 10, 19, 29, Inf)

# Creamos el mapa de calor con líneas verticales en los breaks
ggplot(base_proporciones_df, aes(x = as.numeric(as.character(PuntajeTotal)), y = Variable, fill = Frecuencia)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(title = "Mapa de calor con categorías de riesgo", 
       x = "Puntaje Total", 
       y = "Variable", 
       fill = "Proporción") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_vline(xintercept = risk_category_breaks, color = "gold", size = 0.5, linetype = "dashed")  # Líneas verticales
```

## Explorando los datos desde una perspectiva de redes - Modelo de Ising

Vamos a hacer el análisis de la red psicométrica usando el modelo de Ising.

Los gráficos siguientes muestran la red que se genera para el conjunto de los datos. La bse para la estimación contiene `r NROW(base_igi)` observaciones (o internos).

```{r ising, echo=FALSE, warning=TRUE, message=TRUE, include=TRUE}


# NOTA: Aquí hicimos un Ising apegado al estándar de valores 1 y -1. No obstante, en etapas posteriores esto generaba errores para algunos cálculos que requerían sólo valores positivos, por lo que finalmente lo dejamos con valores 0s y 1s.
# Dejamos igual el código para generar una versión con 1s y -1s por si eventualmente cambianos nuevamente. 
# Convertimos los valores 0 en valore -1 en todas las variables. 

convert_zeros_to_neg1 <- function(df, var_names) { # Iteramos por cada nombre de variable 
  for (col in var_names) { # Verificamos que la columna exista en el data frame 
    if (col %in% names(df)) { # Reemplazamos los valores 0 por -1 
      df[[col]][df[[col]] == 0] <- 0 } else { 
        warning(paste("La columna", col, "no existe en el data frame.")) 
        } 
    } 
  return(df) 
}

base_igi_ising <-  base_igi[,colnames(base_igi) %in% descriptivo_grupal]

base_ising <- convert_zeros_to_neg1(base_igi_ising, descriptivo_grupal)


require(IsingFit)
require(bootnet)
require(qgraph)
require(psychonetrics)

red_dicotomica <- estimateNetwork(base_ising, 
                         default = "IsingFit",
                         #principalDirection =T,
                         labels = descriptivo_grupal)

str(red_dicotomica)

red_dicotomica$graph  # Matriz de adyacencia
red_dicotomica$thresholds
write.csv(red_dicotomica$graph, "pape/ising/matriz_red.csv")

qgraph(red_dicotomica$graph, layout = "spring", labels = colnames(red_dicotomica$graph))

par(mfrow=c(1,2))
plot(red_dicotomica,
     main = "Red estimada para el conjunto de los datos",
     layout = "circle", 
     label.cex=2)

plot(red_dicotomica, 
     layout = "spring", 
     main = "Red estimada para el conjunto de los datos",
     label.cex=2)
dev.off()

```

Algunas métricas de centralidad de cada nodo.

```{r ising_centralidades, echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
library(igraph)

# Convertimos a objeto igraph
grafo <- graph_from_adjacency_matrix(red_dicotomica$graph, mode = "undirected", weighted = TRUE)

pesos_positivos <- abs(E(grafo)$weight)
E(grafo)$weight <- pesos_positivos

# Métricas comunes
centralidad_grado <- degree(grafo)
centralidad_intermediación <- betweenness(grafo)
centralidad_cercanía <- closeness(grafo)

# Compilado de las métricas
cbind(centralidad_grado, centralidad_intermediación,centralidad_cercanía)

```

Un análisis de comunidades usando (cluster_walktrap) arroja lo siguiente:

```{r comunidades,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
comunidades <- cluster_walktrap(grafo)
plot(comunidades, grafo)

comunidades_tabla <- cbind(comunidades$names,comunidades$membership)
comunidades_tabla <- as.data.frame(comunidades_tabla)
comunidades_tabla <- comunidades_tabla[order(comunidades_tabla$V2),]
comunidades_tabla
```

*Estabilidad de la red*

```{r bootnet_global,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
#######################################################
# Esto es lento. No volver a correr hasta version final
#######################################################

# vamos a mirar la estabilidad de las estimaciones hechas de los valores de los links  para robustez.

# estabilidad <- bootnet(red_dicotomica, nBoots = 1000, type = "nonparametric")
# plot(estabilidad)
# 
# # Extraemos la información de estabilidad de edges
# edges_stability <- as.data.frame(estabilidad$bootTable)
# 
# edges_filtered <- dplyr::filter(edges_stability, type == "edge")
# 
# edges_summary <- edges_filtered %>%
#   dplyr::select(name, node1, node2, value, rank_avg, rank_min, rank_max) %>%
#   dplyr::arrange(desc(rank_avg))
# 
# edges_summary <- edges_summary %>%
#   dplyr::arrange(rank_avg)
# 
# # Agregamos una columna con la variabilidad en los rangos
# edges_summary <- edges_summary %>%
#   dplyr::mutate(variability = rank_max - rank_min)
# 
# ggplot(edges_summary, aes(x = rank_avg, y = variability)) +
#   geom_point() +
#   labs(title = "Estabilidad de Conexiones",
#        x = "Rango Promedio (rank_avg)",
#        y = "Variabilidad (rank_max - rank_min)") +
#   theme_minimal()
# 
# edges_summary <- edges_summary %>%
#   dplyr::mutate(
#     classification = dplyr::case_when(
#       rank_avg < 100 & variability < 50 ~ "Estable",       # Baja variabilidad y buen ranking
#       variability > 100 ~ "Inestable",                     # Alta variabilidad
#       rank_avg > 700 ~ "Poco relevante",                   # Alto rank_avg
#       TRUE ~ "Sin clasificar"                              # Cualquier otro caso (opcional)
#     )
#   )
# 
# write.csv(edges_summary, paste0(aqui,"/pape/ising/estabilidad_edges_modelo_general.csv"))
# 
# conexiones_estables <- edges_summary %>%
#   filter(rank_avg < 100, variability < 50)
# 
# conexiones_fuertes <- conexiones_estables %>% 
#   arrange(value) %>% 
#   head(10)
# 
# conexiones_positivas <- edges_summary %>% filter(value > 0)
# 
# ggplot(conexiones_estables, aes(x = value)) +
#   geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
#   labs(title = "Distribución de Valores de Conexión", x = "Valor de Conexión", y = "Frecuencia") +
#   theme_minimal()

# dado que la estabilidad de las conexiones positivas es muy baja, hay que volver a probar con un segundo método de estimación el bootstrap. Como esto es lento, dejar comentado para hacerlo correr de noche

# red_tmfg <- estimateNetwork(datos, default = "TMFG")
# estabilidad_tmfg <- bootnet(red_tmfg, nBoots = 1000, type = "nonparametric")


```

(pendiente) Identifica posibles nodos puente entre comunidades, que podrían representar puntos clave en la red.

En el presente análisis, se considera que la codificación uniforme de las variables y su relación con el riesgo tienen implicaciones directas en los patrones observados en las correlaciones entre ítems. La presencia de un ítem (codificada como valor 1) indica riesgo, por lo que es natural que las relaciones positivas estables entre ítems sean más evidentes en observaciones con altos puntajes de riesgo, donde muchos ítems están presentes simultáneamente. En contraste, para observaciones con bajos puntajes de riesgo, la mayoría de los ítems toman el valor -1 (ausencia), lo que genera una falta de co-activación y podría llevar a correlaciones débiles o incluso negativas entre ellos.

Además, la variabilidad en los puntajes de riesgo introduce complejidad en la dinámica de las correlaciones. Para observaciones con puntajes intermedios, algunos ítems estarán presentes (1) y otros ausentes (-1), generando ruido que reduce la magnitud de las correlaciones positivas o las hace inconsistentes. Por otro lado, las correlaciones negativas tienden a emerger de forma más consistente porque reflejan que, en observaciones con puntajes bajos, la presencia de un ítem está asociada con la ausencia de otro. Este patrón refuerza la hipótesis de que las relaciones negativas son más estables en rangos amplios de los puntajes, mientras que las relaciones positivas podrían depender de un subconjunto específico, como las observaciones con puntajes altos.

En el contexto del análisis bootstrap, esta dinámica se amplifica. Las relaciones más consistentes a través de las muestras bootstrap son aquellas que se replican en un rango amplio de puntajes de riesgo. Por esta razón, las correlaciones negativas emergen como más estables, ya que se reflejan en gran parte del espectro de puntajes (bajos e intermedios). Por el contrario, las correlaciones positivas, aunque podrían ser fuertes, se limitan a un subconjunto más específico de observaciones (puntajes altos), lo que las hace menos replicables y, por ende, menos estables en el proceso bootstrap.

Finalmente, una limitación del análisis psicométrico global es su incapacidad para diferenciar dinámicas específicas de los subgrupos de puntajes. Al considerar todas las observaciones de forma conjunta, las correlaciones positivas que son características de los puntajes altos tienden a diluirse al estar mezcladas con otras observaciones. En cambio, las correlaciones negativas, presentes en un rango más amplio de los puntajes, emergen como las relaciones dominantes y estables. Esta reflexión justifica la necesidad de realizar análisis psicométricos diferenciados por rangos de riesgo para capturar de manera más precisa la naturaleza de las relaciones entre ítems en diferentes niveles de riesgo.

Como una primera exploración vamos a separar la base de datos en tres tercios según los puntaje obtenidos: menos de 19, 20 a 29, 30 o más.

```{r base_ising,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# Ahora analicemos cuáles atributos aparecen correlacionados positiva y negativamente entre sí.

# Creamos categorías de puntajes de riesgo
base_ising <- base_ising %>%
  dplyr::mutate(risk_category = cut(puntaje_total, 
                                    breaks = c(-Inf, 19, 29, Inf),  # Nuevos breaks
                                    labels = c("Low", "Intermediate", "High"),  # Nombres de los grupos
                                    include.lowest = TRUE))

# Analizamos correlaciones por categoría de riesgo
cor_low <- cor(base_ising %>% filter(risk_category == "Low") %>% select(-risk_category))
cor_intermediate <- cor(base_ising %>% filter(risk_category == "Intermediate") %>% select(-risk_category))
cor_high <- cor(base_ising %>% filter(risk_category == "High") %>% select(-risk_category))


library(corrplot)
# corrplot(cor_low, main = "Correlaciones (Puntajes Bajos)")
# corrplot(cor_intermediate, main = "Correlaciones (Puntajes Intermedios)")
# corrplot(cor_high, main = "Correlaciones (Puntajes Altos)")

colores_personalizados <- colorRampPalette(c("darkred", "red", "white", "white", "blue", "darkblue"))(10)
corrplot(cor_low, 
         method = "color", 
         main = "grupo bajo riesgo (< 20)",
         col = colores_personalizados, 
         tl.cex = 0.8,      # Ajustar el tamaño de las etiquetas
         na.label = " ",    # Mostrar valores NA como celdas en blanco
         na.label.col = "white",
         addgrid.col = NA)  # Quitar la cuadrícula si es necesario
corrplot(cor_intermediate, 
         method = "color", 
         main = "grupo riesgo intermedio (20 a 29)",
         col = colores_personalizados, 
         tl.cex = 0.8,      
         na.label = " ",    
         na.label.col = "white",
         addgrid.col = NA)  
corrplot(cor_high, 
         method = "color", 
         main = "grupo riesgo alto (> 29) ",
         col = colores_personalizados, 
         tl.cex = 0.8,      
         na.label = " ",    
         na.label.col = "white",
         addgrid.col = NA)  
```

# Generación de las redes

Dividamos ahora la base en estos tres grupos y veamos las redes que se generan en cada caso usando el modelo de ising. 3 redes con criterios fijos: bajo, medio, alto riesgo.

```{r bootnet_por_riesgo,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# Al trabajar con la base completa para todos los puntajes se pueden estar neteando efectos positivos y negativos de modo tal que no se detecte nada. Así que vamos a hacer ahora un análisis más prolijo dividiendo la base en segmentos. Lo primero será seleccionar rangos de puntajes similares y ver si dentro de esos rangos hay evidencia o no de conexiones diferentes entre atributos. Es decir, evidencia de trayectorias delictuales diferentes que generen el mismo puntaje final.

# Para un primer acercamiento, dividamos la base en tres grupos de riesgo: bajo,intermedio y alto.

# Filtramos datos por grupo de riesgo bajo
red_bajo <- estimateNetwork(
  base_ising %>% 
    filter(risk_category == "Low") %>% 
    select(-risk_category),  # Eliminar la columna de clasificación
  default = "IsingFit"
)

# Filtramos datos por grupo de riesgo intermedio
red_intermedio <- estimateNetwork(
  base_ising %>% 
    filter(risk_category == "Intermediate") %>% 
    select(-risk_category),  # Eliminar la columna de clasificación
  default = "IsingFit"
)

# Filtramos datos por grupo de riesgo alto
red_alto <- estimateNetwork(
  base_ising %>% 
    filter(risk_category == "High") %>% 
    select(-risk_category),  # Eliminar la columna de clasificación
  default = "IsingFit"
)



```

```{r estability,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# Nota: por etapas posteriores dejamos esta exploración comentada. No es necesario volver a correr. 

# Vemaos la estabilidad de las redes/conexiones generadas. 

# Estabilidad para la red de riesgo bajo
# estabilidad_bajo <- bootnet(red_bajo, nBoots = 1000, type = "nonparametric")
# 
# # Estabilidad para la red de riesgo intermedio
# estabilidad_intermedio <- bootnet(red_intermedio, nBoots = 1000, type = "nonparametric")
# 
# # Estabilidad para la red de riesgo alto
# estabilidad_alto <- bootnet(red_alto, nBoots = 1000, type = "nonparametric")
# 
# 
# plot(estabilidad_bajo)
# plot(estabilidad_intermedio)
# plot(estabilidad_alto)

```

Visualizaciones de las redes

```{r visualizacion,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
library(qgraph)

# Visualización de redes
# Extraemos la matriz de pesos de red_bajo, red_medio, red_alto
matriz_pesos_bajo <- red_bajo$graph
matriz_pesos_medio <- red_intermedio$graph
matriz_pesos_alto <- red_alto$graph


# Generarmos los grafos con qgraph para inspección visual de las diferencias
red_criteriofijo_bajo <- qgraph(matriz_pesos_bajo, layout = "spring", title = "Riesgo Bajo")
layout_eganet <- red_criteriofijo_bajo$layout

red_criteriofijo_medio <- qgraph(matriz_pesos_medio, layout = layout_eganet, title = "Riesgo Medio")


red_criteriofijo_alto <- qgraph(matriz_pesos_alto, layout = layout_eganet, title = "Riesgo Alto")

```

*Aproximación usando EGANET para detectar comunidades*

```{r eganet,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
library(EGAnet)

# Veamos ahora si se detectan comunidades diferentes en estas tres redes obtenidas.

# EGA para riesgo bajo
datos_ajustados_bajo <- base_ising %>%
  filter(risk_category == "Low") %>%
  select(-risk_category) %>%
  mutate(across(everything(), ~ . + 1))  # Mapea de -1:1 a 0:2

#ega_bajo <- EGA(datos_ajustados_bajo)
ega_bajo <- EGA(datos_ajustados_bajo)

# EGA para riesgo intermedio
datos_ajustados_bajo <- base_ising %>%
  filter(risk_category == "Intermediate") %>%
  select(-risk_category) %>%
  mutate(across(everything(), ~ . + 1))  # Mapea de -1:1 a 0:2

#ega_intermedio <- EGA(datos_ajustados_bajo)
EGA(datos_ajustados_bajo)

# EGA para riesgo alto
datos_ajustados_alto <- base_ising %>%
  filter(risk_category == "High") %>%
  select(-risk_category) %>%
  mutate(across(everything(), ~ . + 1))  # Mapea de -1:1 a 0:2

#ega_intermedio <- EGA(datos_ajustados_alto)
EGA(datos_ajustados_alto)

# Nota: Las visualizaciones sugieren que hay espacio para una exploración más detallada.


```

# Bootnet

Correlaciones entre redes. Bucles de ventanas de puntajes\
Cada matriz de adyacencia se puede representar como un vector de pares de links o edges con pesos (correlaciones en este caso). Por lo tanto, comparar dos listados de vectores para ver si correlacionan o no es ver si las redes se parecen o no.

```{r diffconfig,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
library(bootnet)

# Ahora que sabemos que parece haber diferencias en las redes para distintos niveles de riesgo (como era lógico esperar), vamos al centro de nuestro objetivo: veamos si para riesgos similares se producen diferencias sustantivas en las redes generadas

# Nota: Este chunck quedará comentado porque quedó perfeccionado más abajo. 

###############################################################################
# Explorar si hay diferentes configuraciones dentro de un mismo puntaje
###############################################################################

# grupo_puntaje <-  list(c(0:9),c(10:20),c(21:29),c(30:41))
# 
# for(j in grupo_puntaje){
#   
#   k_seleccion <- grupo_puntaje[j]
#   sub_bloque <- base_igi %>%
#     filter(puntaje_total %in% k_seleccion)
#   
#   sub_bloque_items <- sub_bloque[, descriptivo_grupal]
#   
#   # (a) Por ejemplo, un cluster analysis simple con distancias a partir
#   # de la activación 0/1 de cada ítem.
#   #   matriz_binaria <- as.matrix(sub_bloque_items)
#   distancias <- dist(matriz_binaria, method = "binary")  # Distancia Jaccard
#   clust_hier <- hclust(distancias, method = "ward.D2")
#   
#   # Decidir cuántos clusters cortar, h. 
#   sub_bloque$sub_cluster <- cutree(clust_hier, k = 3)
#   
#   # (b) Ver cuántos individuos en cada sub_cluster
#   table(sub_bloque$sub_cluster)
#   
#   # (c) Estimar red de Ising por sub_cluster, opcional
#   model_sub_1 <- estimateNetwork(
#     data    = sub_bloque_items[sub_bloque$sub_cluster == 1, ],
#     default = "IsingFit"
#   )
#   model_sub_2 <- estimateNetwork(
#     data    = sub_bloque_items[sub_bloque$sub_cluster == 2, ],
#     default = "IsingFit"
#   )
#   model_sub_3 <- estimateNetwork(
#     data    = sub_bloque_items[sub_bloque$sub_cluster == 3, ],
#     default = "IsingFit"
#   )
#   
#   # (d) Comparar pesos
#   edges_1 <- model_sub_1$graph
#   edges_2 <- model_sub_2$graph
#   edges_3 <- model_sub_3$graph
#   correlacion1_2 <- cor(as.vector(edges_1), as.vector(edges_2))
#   correlacion1_3 <- cor(as.vector(edges_1), as.vector(edges_3))
#   correlacion2_3 <- cor(as.vector(edges_2), as.vector(edges_3))
#   paste("Correlación de los edges entre sub-clusters 1 y 2 con puntajes entre ", min(k_seleccion),
#         " y ",max(k_seleccion), " es:", round(correlacion1_2, 3))
#   paste("Correlación de los edges entre sub-clusters 1 y 3 con puntajes entre ", min(k_seleccion),
#         " y ",max(k_seleccion), " es:", round(correlacion1_3, 3))
#   paste("Correlación de los edges entre sub-clusters 2 y 3 con puntajes entre ", min(k_seleccion),
#         " y ",max(k_seleccion), " es:", round(correlacion2_3, 3))
#   
#   
#   
#   
#   
#   base_kselect <- base_igi %>%
#     filter(puntaje_total %in% k_seleccion)
#   
#   #################################3
#   # Posibles correlaciones
#   
#   # sexo
#   table(base_kselect$SEXO, sub_bloque$sub_cluster)
#   
#   # salud mental
#   table(base_kselect$COD_SALUD_MENTAL, sub_bloque$sub_cluster)
#   
#   # edad
#   datos_combinados_edad <- data.frame(
#     col_base1 = base_kselect$rangos_edad,
#     col_base2 = sub_bloque$sub_cluster
#   )
#   datos_filtrados <- datos_combinados_edad %>%
#     filter(col_base1 != "Sin información" & col_base2 != "Sin información")
#   tabla_cruzada <- table(datos_filtrados$col_base1, datos_filtrados$col_base2)
#   tabla_cruzada
#   
#   # estado civil
#   table(base_kselect$recod_estado_civil, sub_bloque$sub_cluster)
#   
#   # Test chi-cuadrado
#   chisq.test(base_kselect$SEXO, sub_bloque$sub_cluster)
#   chisq.test(base_kselect$COD_SALUD_MENTAL, sub_bloque$sub_cluster)
#   chisq.test(datos_filtrados$col_base1, datos_filtrados$col_base2)
#   chisq.test(base_kselect$recod_estado_civil, sub_bloque$sub_cluster)
#   
# }

```

```{r corr1,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# Nota: Este chunck también quedará comentado porque quedó perfeccionado más abajo. 

###############################################################################
# 1. Definir listas/data frames para ir almacenando los resultados.
###############################################################################
# 
# # Guardar las correlaciones entre subclusters
# cor_results <- data.frame()
# 
# # Guardar los resultados de chi-cuadrado de cada variable
# chi_results <- data.frame()
# 
# # guardar tablas de contingencia como listas de tablas
# cross_tables <- list()
# 
# ###############################################################################
# # 2. Definir rangos de puntajes
# ###############################################################################
# grupo_puntaje <-  list(c(0:9), c(10:19), c(20:29), c(30:41))
# 
# ###############################################################################
# # 3. Bucle principal
# ###############################################################################
# for (j in seq_along(grupo_puntaje)) {
#   
#   # a) Extraer el rango de puntajes seleccionado
#   k_seleccion <- grupo_puntaje[[j]]  
#   
#   # b) Filtrar base por ese rango
#   sub_bloque <- base_igi %>%
#     dplyr::filter(puntaje_total %in% k_seleccion)
#   
#   sub_bloque_items <- sub_bloque[, descriptivo_grupal]
#   
#   # c) Cluster analysis
#   matriz_binaria <- as.matrix(sub_bloque_items)
#   distancias <- dist(matriz_binaria, method = "binary")  # Distancia Jaccard
#   clust_hier <- hclust(distancias, method = "ward.D2")
#   
#   # d) Cortar en k=3 clusters 
#   sub_bloque$sub_cluster <- cutree(clust_hier, k = 3)
#   
#   # e) Estimar redes de Ising por sub_cluster
#   model_sub_1 <- estimateNetwork(
#     data    = sub_bloque_items[sub_bloque$sub_cluster == 1, ],
#     default = "IsingFit"
#   )
#   model_sub_2 <- estimateNetwork(
#     data    = sub_bloque_items[sub_bloque$sub_cluster == 2, ],
#     default = "IsingFit"
#   )
#   model_sub_3 <- estimateNetwork(
#     data    = sub_bloque_items[sub_bloque$sub_cluster == 3, ],
#     default = "IsingFit"
#   )
#   
#   # f) Comparar pesos: correlación de las matrices
#   edges_1 <- model_sub_1$graph
#   edges_2 <- model_sub_2$graph
#   edges_3 <- model_sub_3$graph
#   
#   correlacion1_2 <- cor(as.vector(edges_1), as.vector(edges_2))
#   correlacion1_3 <- cor(as.vector(edges_1), as.vector(edges_3))
#   correlacion2_3 <- cor(as.vector(edges_2), as.vector(edges_3))
#   
#   # g) Guardar esas correlaciones en cor_results
#   cor_results <- rbind(
#     cor_results,
#     data.frame(
#       min_puntaje   = min(k_seleccion),
#       max_puntaje   = max(k_seleccion),
#       cor_1_2       = round(correlacion1_2, 3),
#       cor_1_3       = round(correlacion1_3, 3),
#       cor_2_3       = round(correlacion2_3, 3),
#       n_subcluster1 = sum(sub_bloque$sub_cluster == 1),
#       n_subcluster2 = sum(sub_bloque$sub_cluster == 2),
#       n_subcluster3 = sum(sub_bloque$sub_cluster == 3)
#     )
#   )
#   
#   # h) Tablas de contingencia y test de chi-cuadrado con diferentes variables
#   #    (sexo, salud mental, edad, estado civil...)
#   #    Vamos a hacer la rutina de forma programática para cada variable clave.
#   
#   variables_externas <- c("SEXO", "COD_SALUD_MENTAL", "rangos_edad", "recod_estado_civil")
#   
#   for (var_externa in variables_externas) {
#     
#     # 1) Crear la tabla de contingencia
#     #    Nota: es importante que sub_bloque y base_kselect sean coherentes;
#     tabla <- table(sub_bloque[[var_externa]], sub_bloque$sub_cluster)
#     
#     # 2) Almacenar la tabla en cross_tables (opcional):
#     cross_tables[[paste0(var_externa, "_", min(k_seleccion), "_", max(k_seleccion))]] <- tabla
#     
#     # 3) Ejecutar test de chi-cuadrado, omitiendo filas/columnas vacías si fuese necesario
#     test_result <- chisq.test(tabla)
#     
#     # 4) Guardar resultados en chi_results
#     chi_results <- rbind(
#       chi_results,
#       data.frame(
#         min_puntaje = min(k_seleccion),
#         max_puntaje = max(k_seleccion),
#         variable    = var_externa,
#         X2          = round(test_result$statistic, 2),
#         df          = test_result$parameter,
#         p_value     = test_result$p.value,
#         stringsAsFactors = FALSE
#       )
#     )
#   }
#   
# }
# 
# ###############################################################################
# # 4. Revisión final de los resultados
# ###############################################################################
# 
# # i) Revisar cor_results:
# #    Muestra, para cada rango de puntajes, las correlaciones y el tamaño de subclusters
# cor_results
# 
# # j) Revisar chi_results:
# #    Muestra, para cada rango y variable externa, el chi cuadrado, df y p-value
# chi_results
# 
# # k) Revisar tablas de contingencia (opcional):
# #    cross_tables[["SEXO_0_9"]] por ejemplo, tabla para SEXO en el rango 0-9
# names(cross_tables)
# # Visualizar una tabla en particular
# # cross_tables[["SEXO_0_9"]]

```

Haremos ese ejercicio, estableciendo **Ventanas de 10 puntos** para poder determinar aquél tramo de puntajes donde podría constarse diferencias estructurales. Por lo tanto, la estrategia será: tomar ventanas móviles de puntaje, clusterizar en grupos ese subsegmento de la muestra, estimar las redes que surgen en cada uno de esos subsegmentos usando el modelo de ising, convertir las matrices generadas en edgelists, comparar las correlaciones obtenidas y reportar el resultado.

```{r corr2,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# Ahora que sabemos que parece haber diferencias en las redes para distintos niveles de riesgo (como era lógico esperar), vamos al centro de nuestro objetivo: veamos si para riesgos similares se producen diferencias sustantivas en las redes generadas. Para ello definiremos ventanas de riesgos de 5, 10, 15 puntos y los análisis los haremos dentro de cada ventana.

# Las ventanas serán móviles. Es decir, si la ventana es de 10 puntos. Haremos el cálculo para la ventana que parte en 0 hasta 9, luego de 1 hasta 10, y así sucesivamente hasta 34 a 43.

################################################################################
# 1. Definimos contenedores para resultados
################################################################################
cor_results_sliding <- data.frame()
chi_results_sliding <- data.frame()
cross_tables_sliding <- list()

# Definimos las variables externas a explorar después en las regresiones
variables_externas <- c("SEXO", "COD_SALUD_MENTAL", "rangos_edad", "recod_estado_civil")

################################################################################
# 2. Definimos parámetros de la ventana
################################################################################
window_size <- 10 # Modificar la ventana para otros ejercicios
max_puntaje_observado <- max(base_igi$puntaje_total)  
inicios_ventana <- 0:(max_puntaje_observado - window_size + 1)

################################################################################
# 3. Bucle principal por ventanas "traslapadas"
################################################################################
for (start_val in inicios_ventana) {
  
  # (a) Determinamos el rango de la ventana
  end_val <- start_val + window_size - 5
  rango_puntaje <- start_val:end_val
  
  # (b) Filtramos la base
  sub_bloque <- base_igi %>%
    dplyr::filter(puntaje_total %in% rango_puntaje)
  
  # Revisamos que sub_bloque tenga suficientes observaciones para clusterizar
  if (nrow(sub_bloque) < 50) {
    # Evitemos problemas si el grupo es muy pequeño. .
    next
  }
  
  # (c) Seleccionamos los ítems
  sub_bloque_items <- sub_bloque[, descriptivo_grupal]
  
  # (d) Hacemos el Cluster analysis (distancia Jaccard y Ward.D2)
  matriz_binaria <- as.matrix(sub_bloque_items)
  distancias <- dist(matriz_binaria, method = "binary")
  clust_hier <- hclust(distancias, method = "ward.D2")
  
  # (e) Cortamos en k clusters.
  # Aquí usamos un cluster jerarquico. Hay que darle una vuelta a si usamos algún mecanimos diferente para la generación de los clusters que emerga de los proios datos y no impuestos por nosotros como en este caso ¿por qué 2, 3, 4 clusters?
  sub_bloque$sub_cluster <- cutree(clust_hier, k = 3) # cambiar el número de clusters en pruebas de robustez
  
  # Revisamos los tamaños de cada cluster
  n_c1 <- sum(sub_bloque$sub_cluster == 1)
  n_c2 <- sum(sub_bloque$sub_cluster == 2)
  n_c3 <- sum(sub_bloque$sub_cluster == 3)
  
  # (f) Estimamos redes de Ising por sub_cluster (si hay suficiente n en cada cluster)
  # Nota para después en caso que haya errores para ventanas muy pequeñas: Para evitar errores, podríamos considerar después exigir un mínimo de observaciones en cada cluster. Por ejemplo agregar algo como: if (n_c1 < 10 | n_c2 < 10 | n_c3 < 10) next. 
  
  # Corremos los modelos Ising
  
  model_sub_1 <- estimateNetwork(
    data    = sub_bloque_items[sub_bloque$sub_cluster == 1, ],
    default = "IsingFit"
  )
  model_sub_2 <- estimateNetwork(
    data    = sub_bloque_items[sub_bloque$sub_cluster == 2, ],
    default = "IsingFit"
  )
  model_sub_3 <- estimateNetwork(
    data    = sub_bloque_items[sub_bloque$sub_cluster == 3, ],
    default = "IsingFit"
  )
  
  edges_1 <- model_sub_1$graph
  edges_2 <- model_sub_2$graph
  edges_3 <- model_sub_3$graph
  
  correlacion1_2 <- cor(as.vector(edges_1), as.vector(edges_2))
  correlacion1_3 <- cor(as.vector(edges_1), as.vector(edges_3))
  correlacion2_3 <- cor(as.vector(edges_2), as.vector(edges_3))
  
  # (g) Guardamos las correlaciones y tamaño de clusters en cor_results_sliding
  cor_results_sliding <- rbind(
    cor_results_sliding,
    data.frame(
      min_puntaje   = start_val,
      max_puntaje   = end_val,
      cor_1_2       = round(correlacion1_2, 3),
      cor_1_3       = round(correlacion1_3, 3),
      cor_2_3       = round(correlacion2_3, 3),
      n_subcluster1 = n_c1,
      n_subcluster2 = n_c2,
      n_subcluster3 = n_c3
    )
  )
  
  # (h) Tablas de contingencia y test de chi-cuadrado para variables_externas
  for (var_externa in variables_externas) {
    
    # Construimos tabla de contingencia
    tabla <- table(sub_bloque[[var_externa]], sub_bloque$sub_cluster)
    
    # Almacenamos tabla en la lista
    nombre_tabla <- paste(var_externa, "_", start_val, "_", end_val, sep = "")
    cross_tables_sliding[[nombre_tabla]] <- tabla
    
    # Ejecutamos test de chi-cuadrado 
    test_result <- suppressWarnings(chisq.test(tabla))
    
    chi_results_sliding <- rbind(
      chi_results_sliding,
      data.frame(
        min_puntaje = start_val,
        max_puntaje = end_val,
        variable    = var_externa,
        X2          = round(test_result$statistic, 2),
        df          = test_result$parameter,
        p_value     = test_result$p.value,
        stringsAsFactors = FALSE
      )
    )
  }
  
}

################################################################################
# 4. Al terminar el bucle, revisamos los resultados
################################################################################

# Correlaciones entre matrices, con el rango de puntajes y n de cada subcluster
cor_results_sliding

# Resultados de chi cuadrado
chi_results_sliding

# Tablas de contingencia almacenadas
# names(cross_tables_sliding)  # para ver qué tablas hay

```

Del proceso iterativo anterior se **observan las correlaciones entre los clusters para distintas ventanas de puntaje** siguiente:

```{r plot_corr,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# Para ver si las redes generadas para cada rango de puntaje son distintas o no, calculamos la correlación promedio dentro de cada red y cada rango de puntaje y las comparamos entre redes. Es decir, tomamos la matriz adyacente y la convertimos en edgelists. Sacamos el promedio para cada vector y así tenemos la comparación de cada cluster que parte en cada puntaje y visualizamos. 

library(tidyverse)

cor_long <- cor_results_sliding %>%
  select(min_puntaje, max_puntaje, cor_1_2, cor_1_3, cor_2_3) %>%
  pivot_longer(
    cols = c("cor_1_2", "cor_1_3", "cor_2_3"),
    names_to = "clusters_comparados",
    values_to = "correlacion"
  )

cor_long_b <- cor_long[1:96,]

ggplot(cor_long, aes(x = min_puntaje, y = correlacion, color = clusters_comparados)) +
  geom_line(size = 1) +
  geom_point(size = 2) +  
  theme_minimal() +
  labs(
    x = "Puntaje mínimo de la ventana",
    y = "Correlación entre redes de subclusters",
    color = "Subclusters",
    title = "Correlaciones entre los subclusters para ventanas de puntajes traslapadas"
  ) +
  ylim(0, 1)  


ggplot(cor_long_b, aes(x = min_puntaje, y = correlacion, color = clusters_comparados)) +
  geom_line(size = 1) +
  geom_point(size = 2) +  
  theme_minimal() +
  labs(
    x = "Puntaje mínimo de la ventana",
    y = "Correlación entre redes de subclusters",
    color = "Subclusters",
    title = "Correlaciones entre los subclusters para ventanas de puntajes traslapadas"
  ) +
  ylim(0, 1)  


ggplot(cor_long, aes(x = min_puntaje, y = correlacion)) +
  geom_line(color = "blue", size = 1) +
  geom_point(size = 2) +
  facet_wrap(~ clusters_comparados, ncol = 1) +
  theme_minimal() +
  labs(
    x = "Puntaje mínimo de la ventana",
    y = "Correlación de la red",
    title = "Evolución de la correlación entre subclusters según ventana de puntajes"
  )

ggplot(cor_long_b, aes(x = min_puntaje, y = correlacion)) +
  geom_line(color = "blue", size = 1) +
  geom_point(size = 2) +
  facet_wrap(~ clusters_comparados, ncol = 1) +
  theme_minimal() +
  labs(
    x = "Puntaje mínimo de la ventana",
    y = "Correlación de la red",
    title = "Evolución de la correlación entre subclusters según ventana de puntajes"
  )


cor_long$clusters_comparados_factor <- factor(
  cor_long$clusters_comparados, 
  levels = c("cor_1_2", "cor_1_3", "cor_2_3")
)

cor_long_b$clusters_comparados_factor <- factor(
  cor_long_b$clusters_comparados, 
  levels = c("cor_1_2", "cor_1_3", "cor_2_3")
)

ggplot(cor_long, aes(x = min_puntaje, y = clusters_comparados_factor, fill = correlacion)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "red", high = "blue", mid = "white",
    midpoint = 0.5, limit = c(0,1), space = "Lab",
    name = "Correlación"
  ) +
  theme_minimal() +
  labs(
    x = "Puntaje mínimo de la ventana",
    y = "Par de subclusters",
    title = "Heatmap de correlaciones de redes entre subclusters"
  )


ggplot(cor_long_b, aes(x = min_puntaje, y = clusters_comparados_factor, fill = correlacion)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "red", high = "blue", mid = "white",
    midpoint = 0.5, limit = c(0,1), space = "Lab",
    name = "Correlación"
  ) +
  theme_minimal() +
  labs(
    x = "Puntaje mínimo de la ventana",
    y = "Par de subclusters",
    title = "Heatmap de correlaciones de redes entre subclusters"
  )

```

Justo en esos rangos (alrededor de 14–20) también se ve que la similitud de las redes (correlaciones entre subclusters) baja, lo que sugiere que hay varias “formas” de activar los ítems para producir un puntaje en ese rango.

No solo \[14–19\] y \[15–20\]: también se aprecian p muy bajas en otras ventanas (por ejemplo, \[16–21\], \[17–22\], etc.). Es posible que un mismo “bloque intermedio” (por ejemplo, 14–22) tenga distintas configuraciones de subclusters asociados con variables externas.

Vamos a repetir el ejercicio con ventanas de puntaje ligeramente más grandes para corroborar.

**Ventana de puntajes de 12 puntos**

```{r window12,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

# Si bien el script anterior se puede utilizar cambiando el rango de 10 a 12 puntos, vamos a dejar ambos para efectos de observar el reporte 

################################################################################
# 0. Convertimos los items del IGI en valores -1 y 1 # Lo dejamos en 0 y 1
################################################################################

base_igi <- recode_variables_ptje(base_igi)
base_igi <- convert_zeros_to_neg1(base_igi, descriptivo_grupal)


################################################################################
# 1. Definir contenedores para resultados
################################################################################
cor_results_sliding <- data.frame()
chi_results_sliding <- data.frame()
cross_tables_sliding <- list()

# Definir tus variables externas a explorar
variables_externas <- c("SEXO", "COD_SALUD_MENTAL", "rangos_edad", "recod_estado_civil")

################################################################################
# 2. Definir parámetros de la ventana
################################################################################
window_size <- 12
max_puntaje_observado <- max(base_igi$puntaje_total)  # Ajusta si tu base demuestra que 41 es efectivamente el máximo
inicios_ventana <- 0:(max_puntaje_observado - window_size + 1)

################################################################################
# 3. Bucle principal por ventanas "traslapadas"
################################################################################

for (start_val in inicios_ventana) {

  # (a) Determinar el rango de la ventana
  end_val <- start_val + window_size - 1
  rango_puntaje <- start_val:end_val

  # (b) Filtrar la base
  sub_bloque <- base_igi %>%
    dplyr::filter(puntaje_total %in% rango_puntaje)

  # Revisa que sub_bloque tenga suficientes observaciones para clusterizar
  if (nrow(sub_bloque) < 50) {
    # Evita problemas si el grupo es muy pequeño. Continúa con la siguiente ventana.
    next
  }

  # (c) Seleccionar ítems
  sub_bloque_items <- sub_bloque[, descriptivo_grupal]

  # (d) Cluster analysis (distancia Jaccard y Ward.D2)
  matriz_binaria <- as.matrix(sub_bloque_items)
  distancias <- dist(matriz_binaria, method = "binary")
  clust_hier <- hclust(distancias, method = "ward.D2")

  # (e) Cortar en k=3 clusters (o el número que decidas)
  sub_bloque$sub_cluster <- cutree(clust_hier, k = 3)

  # Revisa tamaño de cada cluster
  n_c1 <- sum(sub_bloque$sub_cluster == 1)
  n_c2 <- sum(sub_bloque$sub_cluster == 2)
  n_c3 <- sum(sub_bloque$sub_cluster == 3)

  # (f) Estimar redes de Ising por sub_cluster si el tamaño es suficiente
  edges_list <- list()
  if (n_c1 >= 100) {
    model_sub_1 <- estimateNetwork(
      data    = sub_bloque_items[sub_bloque$sub_cluster == 1, ],
      default = "IsingFit"
    )
    edges_list[[1]] <- model_sub_1$graph
  }
  if (n_c2 >= 100) {
    model_sub_2 <- estimateNetwork(
      data    = sub_bloque_items[sub_bloque$sub_cluster == 2, ],
      default = "IsingFit"
    )
    edges_list[[2]] <- model_sub_2$graph
  }
  if (n_c3 >= 100) {
    model_sub_3 <- estimateNetwork(
      data    = sub_bloque_items[sub_bloque$sub_cluster == 3, ],
      default = "IsingFit"
    )
    edges_list[[3]] <- model_sub_3$graph
  }

  # Calcular correlaciones solo si hay al menos dos conjuntos de edges
  if (length(edges_list) >= 2) {
    correlaciones <- combn(seq_along(edges_list), 2, function(idx) {
      cor(as.vector(edges_list[[idx[1]]]), as.vector(edges_list[[idx[2]]]))
    })
    correlacion1_2 <- ifelse(1 %in% names(edges_list) & 2 %in% names(edges_list), correlaciones[1], NA)
    correlacion1_3 <- ifelse(1 %in% names(edges_list) & 3 %in% names(edges_list), correlaciones[2], NA)
    correlacion2_3 <- ifelse(2 %in% names(edges_list) & 3 %in% names(edges_list), correlaciones[3], NA)
  } else {
    correlacion1_2 <- correlacion1_3 <- correlacion2_3 <- NA
  }

  # (g) Guardar correlaciones y tamaño de clusters en cor_results_sliding
  cor_results_sliding <- rbind(
    cor_results_sliding,
    data.frame(
      min_puntaje   = start_val,
      max_puntaje   = end_val,
      cor_1_2       = round(correlacion1_2, 3),
      cor_1_3       = round(correlacion1_3, 3),
      cor_2_3       = round(correlacion2_3, 3),
      n_subcluster1 = n_c1,
      n_subcluster2 = n_c2,
      n_subcluster3 = n_c3
    )
  )

  # (h) Tablas de contingencia y test de chi-cuadrado para variables_externas
  for (var_externa in variables_externas) {

    # Construir tabla de contingencia
    tabla <- table(sub_bloque[[var_externa]], sub_bloque$sub_cluster)

    # Almacenar tabla en la lista (puedes indexar con una cadena descriptiva)
    nombre_tabla <- paste(var_externa, "_", start_val, "_", end_val, sep = "")
    cross_tables_sliding[[nombre_tabla]] <- tabla

    # Ejecutar test de chi-cuadrado (si no hay celdas vacías en las filas/cols)
    test_result <- suppressWarnings(chisq.test(tabla))

    chi_results_sliding <- rbind(
      chi_results_sliding,
      data.frame(
        min_puntaje = start_val,
        max_puntaje = end_val,
        variable    = var_externa,
        X2          = round(test_result$statistic, 2),
        df          = test_result$parameter,
        p_value     = test_result$p.value,
        stringsAsFactors = FALSE
      )
    )
  }
}

```

**Ventana de 12 guardando particularmnte el grupo 14**

```{r window12_14,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
###############################################################################
# 1. Definir contenedores generales (todas las ventanas)
###############################################################################
cor_results_sliding <- data.frame()
chi_results_sliding <- data.frame()
cross_tables_sliding <- list()

# Definir tus variables externas a explorar
variables_externas <- c("SEXO", "COD_SALUD_MENTAL", "rangos_edad", "recod_estado_civil")

###############################################################################
# 2. Definir contenedores específicos para la ventana que parte en 14
###############################################################################
cor_results_14 <- data.frame()           # Guardará correlaciones de subclusters para la ventana 14
chi_results_14 <- data.frame()           # Guardará resultados de chi-cuadrado para la ventana 14
cross_tables_14 <- list()                # Guardará tablas de contingencia para la ventana 14

model_sub_1_14 <- NULL                   # Para conservar los modelos Ising
model_sub_2_14 <- NULL
model_sub_3_14 <- NULL
sub_bloque_14  <- NULL                   # Para conservar el data frame de esa ventana
sub_bloque_items_14 <- NULL

###############################################################################
# 3. Definir parámetros de la ventana
###############################################################################
window_size <- 12
max_puntaje_observado <- max(base_igi$puntaje_total)
inicios_ventana <- 0:(max_puntaje_observado - window_size + 1)

###############################################################################
# 4. Bucle principal por ventanas traslapadas
###############################################################################
for (start_val in inicios_ventana) {

  # (a) Determinar el rango de la ventana
  end_val <- start_val + window_size - 1
  rango_puntaje <- start_val:end_val

  # (b) Filtrar la base
  sub_bloque <- base_igi %>%
    dplyr::filter(puntaje_total %in% rango_puntaje)

  # Verificar número de casos
  if (nrow(sub_bloque) < 50) {
    next
  }

  # (c) Seleccionar ítems
  sub_bloque_items <- sub_bloque[, descriptivo_grupal]

  # (d) Análisis cluster
  matriz_binaria <- as.matrix(sub_bloque_items)
  distancias <- dist(matriz_binaria, method = "binary")
  clust_hier <- hclust(distancias, method = "ward.D2")

  # generamos los k grupos según similitud. NOTA: Éste paso es el que menos me acomoda porque estamos arbitrariamente generando k grupos. Sería ideal intentar algún método que genere los grupos de forma automática o algún criterio diferente a la mera decisión arbitraria.
  
  sub_bloque$sub_cluster <- cutree(clust_hier, k = 3)

  n_c1 <- sum(sub_bloque$sub_cluster == 1)
  n_c2 <- sum(sub_bloque$sub_cluster == 2)
  n_c3 <- sum(sub_bloque$sub_cluster == 3)

  # (e) Estimar redes Ising solo si n del cluster >= 100
  edges_list <- list()
  if (n_c1 >= 100) {
    model_sub_1 <- estimateNetwork(
      data    = sub_bloque_items[sub_bloque$sub_cluster == 1, ],
      default = "IsingFit"
    )
    edges_list[[1]] <- model_sub_1$graph
  }
  if (n_c2 >= 100) {
    model_sub_2 <- estimateNetwork(
      data    = sub_bloque_items[sub_bloque$sub_cluster == 2, ],
      default = "IsingFit"
    )
    edges_list[[2]] <- model_sub_2$graph
  }
  if (n_c3 >= 100) {
    model_sub_3 <- estimateNetwork(
      data    = sub_bloque_items[sub_bloque$sub_cluster == 3, ],
      default = "IsingFit"
    )
    edges_list[[3]] <- model_sub_3$graph
  }

  # Calcular correlaciones solo si hay al menos dos redes disponibles
  if (length(edges_list) >= 2) {
    correlaciones <- combn(seq_along(edges_list), 2, function(idx) {
      cor(as.vector(edges_list[[idx[1]]]), as.vector(edges_list[[idx[2]]]))
    })
    correlacion1_2 <- ifelse(1 %in% names(edges_list) & 2 %in% names(edges_list), correlaciones[1], NA)
    correlacion1_3 <- ifelse(1 %in% names(edges_list) & 3 %in% names(edges_list), correlaciones[2], NA)
    correlacion2_3 <- ifelse(2 %in% names(edges_list) & 3 %in% names(edges_list), correlaciones[3], NA)
  } else {
    correlacion1_2 <- correlacion1_3 <- correlacion2_3 <- NA
  }

  # (f) Guardar en contenedores generales (todas las ventanas)
  cor_results_sliding <- rbind(
    cor_results_sliding,
    data.frame(
      min_puntaje   = start_val,
      max_puntaje   = end_val,
      cor_1_2       = round(correlacion1_2, 3),
      cor_1_3       = round(correlacion1_3, 3),
      cor_2_3       = round(correlacion2_3, 3),
      n_subcluster1 = n_c1,
      n_subcluster2 = n_c2,
      n_subcluster3 = n_c3
    )
  )

  # (g) Test de chi-cuadrado y tablas de contingencia
  for (var_externa in variables_externas) {
    tabla <- table(sub_bloque[[var_externa]], sub_bloque$sub_cluster)
    nombre_tabla <- paste(var_externa, "_", start_val, "_", end_val, sep = "")
    cross_tables_sliding[[nombre_tabla]] <- tabla

    test_result <- suppressWarnings(chisq.test(tabla))

    chi_results_sliding <- rbind(
      chi_results_sliding,
      data.frame(
        min_puntaje = start_val,
        max_puntaje = end_val,
        variable    = var_externa,
        X2          = round(test_result$statistic, 2),
        df          = test_result$parameter,
        p_value     = test_result$p.value,
        stringsAsFactors = FALSE
      )
    )
  }

  #############################################################################
  # 5. GUARDAR en contenedores ESPECÍFICOS SI start_val == 14
  #############################################################################
  if (start_val == 14) {
    # (a) Guardar correlaciones
    cor_results_14 <- data.frame(
      min_puntaje   = start_val,
      max_puntaje   = end_val,
      cor_1_2       = round(correlacion1_2, 3),
      cor_1_3       = round(correlacion1_3, 3),
      cor_2_3       = round(correlacion2_3, 3),
      n_subcluster1 = n_c1,
      n_subcluster2 = n_c2,
      n_subcluster3 = n_c3
    )

    # (b) Guardar resultados de chi-cuadrado
    chi_results_14 <- chi_results_sliding %>%
      dplyr::filter(min_puntaje == 14)

    # (c) Guardar las tablas de contingencia
    for (var_externa in variables_externas) {
      nombre_tabla_14 <- paste(var_externa, "_", start_val, "_", end_val, sep = "")
      cross_tables_14[[nombre_tabla_14]] <- cross_tables_sliding[[nombre_tabla_14]]
    }

    # (d) Guardar los modelos y el sub_bloque
    if (1 %in% names(edges_list)) model_sub_1_14 <- model_sub_1
    if (2 %in% names(edges_list)) model_sub_2_14 <- model_sub_2
    if (3 %in% names(edges_list)) model_sub_3_14 <- model_sub_3

    sub_bloque_14       <- sub_bloque
    sub_bloque_items_14 <- sub_bloque_items
  }

}
  # Fin del for

###############################################################################
# 6. Al terminar, tenemos:
# - cor_results_sliding (todas las ventanas)
# - chi_results_sliding (todas las ventanas)
# - cross_tables_sliding (todas las ventanas)
# Y además objetos específicos de la ventana que inicia en 14:
# - cor_results_14, chi_results_14, cross_tables_14, model_sub_1_14, etc.
###############################################################################

# Revisión final
cor_results_sliding
chi_results_sliding
names(cross_tables_sliding)

# Objetos de la ventana que comienza en 14
cor_results_14
chi_results_14
names(cross_tables_14)     # Tablas de contingencia
model_sub_1_14             # Modelo Ising subcluster 1
model_sub_2_14             # Modelo Ising subcluster 2
model_sub_3_14             # Modelo Ising subcluster 3

```

Plot de las correlaciones

```{r plot_corr2,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

ggplot(cor_long, aes(x = min_puntaje, y = correlacion, color = clusters_comparados)) +
  geom_line(size = 1) +
  geom_point(size = 2) +  # opcional, para marcar cada punto
  theme_minimal() +
  labs(
    x = "Puntaje mínimo de la ventana",
    y = "Correlación entre redes de subclusters",
    color = "Subclusters",
    title = "Correlaciones entre los subclusters para ventanas de puntajes traslapadas"
  ) +
  ylim(0, 1)  # para forzar el eje Y de 0 a 1


ggplot(cor_long, aes(x = min_puntaje, y = correlacion)) +
  geom_line(color = "blue", size = 1) +
  geom_point(size = 2) +
  facet_wrap(~ clusters_comparados, ncol = 1) +
  theme_minimal() +
  labs(
    x = "Puntaje mínimo de la ventana",
    y = "Correlación de la red",
    title = "Evolución de la correlación entre subclusters según ventana de puntajes"
  )


cor_long$clusters_comparados_factor <- factor(
  cor_long$clusters_comparados, 
  levels = c("cor_1_2", "cor_1_3", "cor_2_3")
)

ggplot(cor_long, aes(x = min_puntaje, y = clusters_comparados_factor, fill = correlacion)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "red", high = "blue", mid = "white",
    midpoint = 0.5, limit = c(0,1), space = "Lab",
    name = "Correlación"
  ) +
  theme_minimal() +
  labs(
    x = "Puntaje mínimo de la ventana",
    y = "Par de subclusters",
    title = "Heatmap de correlaciones de redes entre subclusters"
  )
```

# Analisis comparativo de la estabibilidad de las conexiones e las tres redes (Subcluster 1, 2 y 3)

En los tres análisis realizados (NCT_12_14, NCT_23_14 y NCT_13_14), se aplicó el Network Comparison Test para datos binarios, comparando cada par de subclusters en términos de:

Invariancia de la estructura global (Network Invariance Test): Evalúa si los patrones de conexión entre ítems (edges) difieren en conjunto. Invariancia de la fuerza global (Global Strength Invariance Test): Evalúa si la suma total de los pesos de las conexiones en cada red difiere. Edges específicos (Edge Invariance Test): Muestra p-values para cada par de ítems, indicando si un edge puntual difiere entre los subclusters.

```{r ,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
###############################################################################
# 1. Extraer datos de cada subcluster en la ventana 14
###############################################################################
datos_sub1_14 <- sub_bloque_items_14[sub_bloque_14$sub_cluster == 1, ]
datos_sub2_14 <- sub_bloque_items_14[sub_bloque_14$sub_cluster == 2, ]
datos_sub3_14 <- sub_bloque_items_14[sub_bloque_14$sub_cluster == 3, ]

# Si 'datos_sub1_14' es el data frame con los ítems binarios del subcluster 1:

datos_sub1_14 <- na.omit(datos_sub1_14)
datos_sub2_14 <- na.omit(datos_sub2_14)
datos_sub3_14 <- na.omit(datos_sub3_14)
```

El segmento con el que finalmente vamos a trabajar contiene `r NROW(datos_sub1_14) + NROW(datos_sub2_14) + NROW(datos_sub3_14)` observaciones. Divididas en `r NROW(datos_sub1_14)` para el primer grupo, `r NROW(datos_sub2_14)` para el segundo grupo y `r NROW(datos_sub3_14)` para el tercer grupo.

# model_sub_1_14, model_sub_2_14, model_sub_3_14

```{r ,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}


# Nos quedamos con la red que parte en ptje 14. Las estimamos una vez más para guardarlas

model_sub_1_14 <- estimateNetwork(
      data    = sub_bloque_items_14[sub_bloque_14$sub_cluster == 1, ],
      default = "IsingFit"
)

model_sub_2_14 <- estimateNetwork(
      data    = sub_bloque_items_14[sub_bloque_14$sub_cluster == 2, ],
      default = "IsingFit"
)

model_sub_3_14 <- estimateNetwork(
      data    = sub_bloque_items_14[sub_bloque_14$sub_cluster == 3, ],
      default = "IsingFit"
)

library(qgraph)

# Crear el data frame con las coordenadas
circle_coords <- data.frame(
  Node = paste0("Node", 1:43),
  x = c(1.000000, 0.989343, 0.957601, 0.905448, 0.833998, 0.744772, 
        0.639673, 0.520940, 0.391105, 0.252933, 0.109371, -0.036522, 
        -0.181637, -0.322880, -0.457242, -0.581859, -0.694074, -0.791496, 
        -0.872049, -0.934016, -0.976076, -0.997332, -0.997332, -0.976076, 
        -0.934016, -0.872049, -0.791496, -0.694074, -0.581859, -0.457242, 
        -0.322880, -0.181637, -0.036522, 0.109371, 0.252933, 0.391105, 
        0.520940, 0.639673, 0.744772, 0.833998, 0.905448, 0.957601, 0.989343),
  y = c(0.000000, 0.145601, 0.288099, 0.424457, 0.551768, 0.667319, 
        0.768647, 0.853593, 0.920346, 0.967484, 0.994001, 0.999333, 
        0.983366, 0.946440, 0.889342, 0.813290, 0.719903, 0.611174, 
        0.489418, 0.357231, 0.217430, 0.072995, -0.072995, -0.217430, 
        -0.357231, -0.489418, -0.611174, -0.719903, -0.813290, -0.889342, 
        -0.946440, -0.983366, -0.999333, -0.994001, -0.967484, -0.920346, 
        -0.853593, -0.768647, -0.667319, -0.551768, -0.424457, -0.288099, -0.145601)
)

layout_manual <- as.matrix(circle_coords[, c("x", "y")])

# Paso 1: Extraer la matriz de pesos de cada red (estimada con IsingFit, mgm, etc.)
# Suponiendo que model_sub_1_14$graph es la matriz de conexiones (edges) de la red
adj1 <- model_sub_1_14$graph
adj2 <- model_sub_2_14$graph
adj3 <- model_sub_3_14$graph

library(igraph)

# Configurar el espacio gráfico para tres paneles en una fila

# Generar un layout común basado en la primera red
adj_positive_1 <- ifelse(adj1 > 0, adj1, 0)
g_positive_1 <- graph_from_adjacency_matrix(adj_positive_1, mode = "undirected", weighted = TRUE)
layout_common <- layout_with_fr(g_positive_1, niter = 500, grid = "nogrid")  # Layout común
# layout_common <- layout_in_circle(g_positive_1)  # Layout común

# Función para graficar una red con relaciones positivas y negativas
plot_cluster <- function(adj, title, layout_common) {
  # Separar relaciones positivas y negativas
  adj_positive <- ifelse(adj > 0, adj, 0)
  adj_negative <- ifelse(adj < 0, abs(adj), 0)
  
  g_positive <- graph_from_adjacency_matrix(adj_positive, mode = "undirected", weighted = TRUE)
  g_negative <- graph_from_adjacency_matrix(adj_negative, mode = "undirected", weighted = TRUE)
  
  # Graficar relaciones positivas
  plot(g_positive, 
       layout = layout_common, 
       edge.color = "blue",  # Color de arcos positivos
       edge.width = E(g_positive)$weight * 5, 
       vertex.color = "lightgray", 
       vertex.label.color = "black", 
       vertex.label.cex = 0.7,  # Tamaño reducido de etiquetas
       edge.curved = 0.2,       # Arcos curvos
       main = title)
  
  # Superponer relaciones negativas
  plot(g_negative, 
       layout = layout_common, 
       edge.color = "red",    # Color de arcos negativos
       edge.width = E(g_negative)$weight * 5, 
       vertex.color = NA,     # No cambiar los nodos
       vertex.label = NA,     # No cambiar las etiquetas
       add = TRUE,            # Superponer
       edge.curved = 0.2)     # Arcos curvos
}

png("pape/ising/redes_14.png", width = 1800, height = 600)  

# Tamaño ajustado para tres redes
par(mfrow = c(1, 3), mar = c(2, 2, 2, 2))       # Configuración para tres paneles

# Red 1
plot_cluster(adj1, "Red del cluster 1", layout_common)

# Red 2
plot_cluster(adj2, "Red del cluster 2", layout_common)

# Red 3
plot_cluster(adj3, "Red del cluster 3", layout_common)

# Cerrar el dispositivo gráfico
dev.off()

#################################################################################
# Usar los resultados del test de diferencias entre las redes para determinar dónde están las diferencias estadísticamente relevantes.

x <- read.csv("pape/ising/nct_13_14_pvalues.csv")
x <- x[order(x$pvals_ajustados),]
x.diff <- x[x$pvals_ajustados<0.05,]
pares.diff <- cbind(as.character(x.diff$Var1),as.character(x.diff$Var2))

# Función para graficar una red resaltando diferencias estadísticas
plot_cluster_diff <- function(adj, pares_diff, title, layout_common) {
  # Crear el grafo desde la matriz de adyacencia
  g <- graph_from_adjacency_matrix(adj, mode = "undirected", weighted = TRUE)
  
  # Crear un vector de colores para todos los arcos (gris por defecto)
  edge_colors <- rep("gray", ecount(g))
  
  # Obtener la lista de arcos del grafo
  edges <- get.edgelist(g, names = TRUE)
  
  # Resaltar las diferencias significativas en pares.diff
  for (i in seq_len(nrow(edges))) {
    edge <- edges[i, ]
    if (any(apply(pares_diff, 1, function(p) all(p == edge) || all(rev(p) == edge)))) {
      weight <- adj[edge[1], edge[2]]
      edge_colors[i] <- ifelse(weight > 0, "blue", "red")
    }
  }
  
  # Graficar la red
  plot(g, 
       layout = layout_common, 
       edge.color = edge_colors,  # Usar colores definidos
       edge.width = 2, 
       vertex.color = "lightgray", 
       vertex.label.color = "black", 
       vertex.label.cex = 0.7, 
       edge.curved = 0.2, 
       main = title)
}

# Crear un layout común basado en adj1
adj_positive_1 <- ifelse(adj1 > 0, adj1, 0)
g_positive_1 <- graph_from_adjacency_matrix(adj_positive_1, mode = "undirected", weighted = TRUE)
layout_common <- layout_with_fr(g_positive_1, niter = 500)

# Preparar pares.diff
pares.diff_indices <- apply(pares.diff, 1, function(par) {
  c(which(rownames(adj1) == par[1]), which(rownames(adj1) == par[2]))
})
pares.diff_indices <- t(pares.diff_indices)

# Graficar las redes adj1 y adj3
png("pape/ising/redes_14_diferencias.png", width = 1800, height = 600)
par(mfrow = c(1, 2), mar = c(2, 2, 2, 2))  # Dos paneles en una fila

plot_cluster_diff(adj1, pares.diff, "Red del cluster 1", layout_common)
plot_cluster_diff(adj3, pares.diff, "Red del cluster 3", layout_common)
dev.off()

####################
# una version idéntica a la anterior donde los edges grises se dejan en blanco
# Función para graficar una red resaltando diferencias estadísticas
plot_cluster_diff <- function(adj, pares_diff, title, layout_common) {
  # Crear el grafo desde la matriz de adyacencia
  g <- graph_from_adjacency_matrix(adj, mode = "undirected", weighted = TRUE)
  
  # Crear un vector de colores para todos los arcos (gris por defecto)
  edge_colors <- rep(NA, ecount(g))
  
  # Obtener la lista de arcos del grafo
  edges <- get.edgelist(g, names = TRUE)
  
  # Resaltar las diferencias significativas en pares.diff
  for (i in seq_len(nrow(edges))) {
    edge <- edges[i, ]
    if (any(apply(pares_diff, 1, function(p) all(p == edge) || all(rev(p) == edge)))) {
      weight <- adj[edge[1], edge[2]]
      edge_colors[i] <- ifelse(weight > 0, "blue", "red")
    }
  }
  
  # Graficar la red
  plot(g, 
       layout = layout_common, 
       edge.color = edge_colors,  # Usar colores definidos
       edge.width = 2, 
       vertex.color = "lightgrey", 
       vertex.label.color = "black", 
       vertex.label.cex = 0.7, 
       edge.curved = 0.2, 
       main = title)
}

# Crear un layout común basado en adj1
adj_positive_1 <- ifelse(adj1 > 0, adj1, 0)
g_positive_1 <- graph_from_adjacency_matrix(adj_positive_1, mode = "undirected", weighted = TRUE)
layout_common <- layout_with_fr(g_positive_1, niter = 500)

# Preparar pares.diff
pares.diff_indices <- apply(pares.diff, 1, function(par) {
  c(which(rownames(adj1) == par[1]), which(rownames(adj1) == par[2]))
})
pares.diff_indices <- t(pares.diff_indices)

# Graficar las redes adj1 y adj3
png("pape/ising/redes_14_diferencias_destacadas.png", width = 1800, height = 600)
par(mfrow = c(1, 2), mar = c(2, 2, 2, 2))  # Dos paneles en una fila

plot_cluster_diff(adj1, pares.diff, "Red del cluster 1", layout_common)
plot_cluster_diff(adj3, pares.diff, "Red del cluster 3", layout_common)
dev.off()


```

# Algunas medidas de centralidad de cada nodo

```{r ,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}


# Calcular centralidad para la red 1
central1 <- centrality_auto(adj1)
central1$centrality

# Calcular centralidad para la red 2
central2 <- centrality_auto(adj2)
central2$centrality

# Calcular centralidad para la red 3
central3 <- centrality_auto(adj3)
central3$centrality


centralityPlot(adj1, include = c("Strength"))
centralityPlot(adj2, include = c("Strength"))
centralityPlot(adj3, include = c("Strength"))

```

# ¿Son realmente distintas estas redes?

```{r ,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
###############################################################################
#############  OJO: ESTA PARTE DEMORA 5 HORAS POR CADA RED APROXIMADAMENTE
###############################################################################
# library(NetworkComparisonTest)
# 
# ###############################################################################
# # 3. Comparaciones pairwise
# ###############################################################################
# # 3.1. Subcluster 1 vs. Subcluster 2
# NCT_12_14 <- NCT(
#   data1       = datos_sub1_14,
#   data2       = datos_sub2_14,
#   binary.data = TRUE,
#   test.edges  = TRUE,
#   edges       = "all",
#   it          = 1000
# )
# summary(NCT_12_14)
# 
# # 3.2. Subcluster 1 vs. Subcluster 3
# NCT_13_14 <- NCT(
#   data1       = datos_sub1_14,
#   data2       = datos_sub3_14,
#   binary.data = TRUE,
#   test.edges  = TRUE,
#   edges       = "all",
#   it          = 1000
# )
# summary(NCT_13_14)
# 
# # 3.3. Subcluster 2 vs. Subcluster 3
# NCT_23_14 <- NCT(
#   data1       = datos_sub2_14,
#   data2       = datos_sub3_14,
#   binary.data = TRUE,
#   test.edges  = TRUE,
#   edges       = "all",
#   it          = 1000
# )
# summary(NCT_23_14)
# 
# save(NCT_12_14, NCT_13_14, NCT_23_14, 
#      file = paste0(aqui,"/pape/ising/NCT_subclusters_14.RData"))
# 
# res_summary_12_14 <- summary(NCT_12_14)
# res_summary_13_14 <- summary(NCT_13_14)
# res_summary_23_14 <- summary(NCT_23_14)
# 
# save(res_summary_12_14, 
#      res_summary_13_14, 
#      res_summary_23_14,
#      file = paste0(aqui,"/pape/ising/NCT_sub14_summary.RData"))

# pvals_crudos <- NCT_12_14$einv.pvals$`p-value`
# pvals_ajustados <- p.adjust(pvals_crudos, method = "BH")
# NCT_12_14$einv.pvals$pvals_ajustados <- pvals_ajustados
# 
# pvals_crudos <- NCT_13_14$einv.pvals$`p-value`
# pvals_ajustados <- p.adjust(pvals_crudos, method = "BH")
# NCT_13_14$einv.pvals$pvals_ajustados <- pvals_ajustados
# 
# pvals_crudos <- NCT_23_14$einv.pvals$`p-value`
# pvals_ajustados <- p.adjust(pvals_crudos, method = "BH")
# NCT_23_14$einv.pvals$pvals_ajustados <- pvals_ajustados
# 
# write.csv(NCT_12_14$einv.pvals,paste0(aqui,"/pape/ising/nct_12_14_pvalues.csv"))
# write.csv(NCT_13_14$einv.pvals,paste0(aqui,"/pape/ising/nct_13_14_pvalues.csv"))
# write.csv(NCT_23_14$einv.pvals,paste0(aqui,"/pape/ising/nct_23_14_pvalues.csv"))

```

1)  Subcluster 1 vs. Subcluster 2 (NCT_12_14) Estructura global: Diferente de forma estadísticamente significativa (p \~ 0.001).\
    Fuerza global: Diferente también (p \~ 0.002), con Subcluster 2 mostrando un valor de fuerza total más alto (\~87) que Subcluster 1 (\~71).\
    Edges específicos: Varios con p \< 0.05, por ejemplo (HD1–HD2, HD1–HD3), lo que refuerza la idea de que las redes difieren en conexiones puntuales y en la suma de todas ellas.\
    Interpretación: Subcluster 1 y 2 presentan configuraciones de red claramente distintas, tanto en la distribución global de conexiones como en la fortaleza total.

2)  Subcluster 2 vs. Subcluster 3 (NCT_23_14)\
    Estructura global: Diferente (p \~ 0.001), por lo que las redes no son equivalentes en la matriz de conexiones. Fuerza global: No difiere de manera significativa (p \~ 0.19). Aunque la estructura de las conexiones cambia, la suma total de pesos (fuerza) no muestra una diferencia estadísticamente confiable.\
    Edges específicos: Aparecen algunos con p \< 0.05, por ejemplo (HD1–HD5), indicando divergencias en conexiones concretas. Muchos otros edges no difieren (p \~ 1.0).\
    Interpretación: Subcluster 2 y 3 se distinguen en cómo están distribuidas las conexiones, pero globalmente sus redes muestran una suma de pesos similar.

En los tres análisis realizados (NCT_12_14, NCT_23_14 y NCT_13_14), se aplicó el Network Comparison Test para datos binarios, comparando cada par de subclusters en términos de:

Invariancia de la estructura global (Network Invariance Test): Evalúa si los patrones de conexión entre ítems (edges) difieren en conjunto.\
Invariancia de la fuerza global (Global Strength Invariance Test): Evalúa si la suma total de los pesos de las conexiones en cada red difiere.\
Edges específicos (Edge Invariance Test): Muestra p-values para cada par de ítems, indicando si un edge puntual difiere entre los subclusters.\
1) Subcluster 1 vs. Subcluster 2 (NCT_12_14)\
Estructura global: Diferente de forma estadísticamente significativa (p \~ 0.001).\
Fuerza global: Diferente también (p \~ 0.002), con Subcluster 2 mostrando un valor de fuerza total más alto (\~87) que Subcluster 1 (\~71).\
Edges específicos: Varios con p \< 0.05, por ejemplo (HD1–HD2, HD1–HD3), lo que refuerza la idea de que las redes difieren en conexiones puntuales y en la suma de todas ellas.\
Interpretación: Subcluster 1 y 2 presentan configuraciones de red claramente distintas, tanto en la distribución global de conexiones como en la fortaleza total.

2)  Subcluster 2 vs. Subcluster 3 (NCT_23_14)\
    Estructura global: Diferente (p \~ 0.001), por lo que las redes no son equivalentes en la matriz de conexiones. Fuerza global: No difiere de manera significativa (p \~ 0.19). Aunque la estructura de las conexiones cambia, la suma total de pesos (fuerza) no muestra una diferencia estadísticamente confiable.\
    Edges específicos: Aparecen algunos con p \< 0.05, por ejemplo (HD1–HD5), indicando divergencias en conexiones concretas. Muchos otros edges no difieren (p \~ 1.0).\
    Interpretación: Subcluster 2 y 3 se distinguen en cómo están distribuidas las conexiones, pero globalmente sus redes muestran una suma de pesos similar.

3)  Subcluster 1 vs. Subcluster 3 (NCT_13_14)\
    Estructura global: No se observan diferencias significativas (p \~ 0.43).\
    Fuerza global: Tampoco difiere de manera significativa (p \~ 0.68).\
    Edges específicos: Algunos edges puntuales (p. ej., HD1–HD2, HD1–HD3, HD1–HD5) muestran p \< 0.05 sin corrección. Sin embargo, el resultado general (estructura y fuerza global) indica que las redes son, en conjunto, bastante parecidas.\
    Interpretación: Subcluster 1 y 3 no difieren en la medida global de sus conexiones, ni en la fuerza total de la red. Aunque pueden existir divergencias menores en edges particulares, no se detecta un patrón significativo a nivel global.

**Conclusión Global**\
Subcluster 2 es el que más difiere de los otros dos:

Al compararlo con Subcluster 1, se hallan diferencias tanto en la estructura como en la fuerza global.\
Al compararlo con Subcluster 3, cambian las conexiones globales, pero su “fortaleza total” no difiere mucho.\
Subcluster 1 y 3 muestran similitudes sustanciales:

Ni la estructura de red ni la fuerza global resultan diferentes de forma estadísticamente significativa, lo que sugiere que, en conjunto, esos dos subclusters comparten una configuración más afín.

Edges específicos:

En los casos donde la estructura global difiere (1 vs 2, 2 vs 3), el Edge Invariance Test señala ciertos pares de ítems con variación significativa (p. ej., conexiones que incluyen HD1).\
En la comparación 1 vs 3, aunque aparecen algunos edges con p \< 0.05, el test global no es significativo, por lo que deben interpretarse con cautela.

En la práctica, cuando se dice que una red tiene mayor fortaleza total (global strength) que otra, significa que la suma de los pesos de las conexiones (edges) en esa red es superior. En un contexto de psicometría de redes o de ítems binarios, se suele interpretar así:

Mayor interconexión entre los nodos: Una red con alta fortaleza total indica que, en promedio, los ítems (nodos) ejercen influencias (o se asocian) más intensamente unos con otros. Es decir, pequeños cambios en un ítem pueden “propagarse” más fácilmente al resto.

Impulsores o facilitadores mutuos: Si es un instrumento de riesgo, por ejemplo, mayor fortaleza total puede sugerir que la activación de un factor (como problemas familiares) potencia la aparición de otros (p. ej., conductas delictivas, consumo de drogas, etc.) en mayor medida que en una red con menor fortaleza.

Posible implicación en la gravedad o la consolidación de rasgos:

En redes clínicas, se ha sugerido que los síntomas con redes muy “fuertes” tienden a consolidarse y dificultar la recuperación, porque los problemas se retroalimentan. En redes de factores de riesgo, una fortaleza global más alta puede implicar que las personas con ciertos factores activos se vean más “atrapadas” en circuitos de riesgo. No obstante, una fortaleza mayor no siempre se traduce en consecuencias negativas: depende de la naturaleza de los ítems y de la interpretación teórica que se dé a esos vínculos. En un instrumento que evalúa factores protectores, una red más “fuerte” podría incluso indicar un mayor sostén interno entre ellos.

En síntesis, una red con mayor fortaleza total está más conectada y reacciona de forma más interdependiente. Sus implicancias son que los nodos (ítems o factores) tienden a activarse juntos y a sostenerse mutuamente, lo cual puede magnificar tanto efectos positivos (protección) como negativos (riesgo), según el contexto de los ítems en cuestión.

# Regresiones

Veamos ahora la conexión con reincidencia ¿ganamos poder explicativo al incorporar las redes en el análisis?

Partimos con:

```{r base0,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

base_igi_14 <- base_igi

print("Modelo: puntaje explica reincidencia")
mod0 <- glm(reincidencia ~ puntaje_total,
           family = binomial(link="logit"),
           data = base_igi_14)
summary(mod0)
exp(coef(mod0))

print("Modelo: puntaje + covariables explican reincidencia")
mod0b <- glm(reincidencia ~ puntaje_total + 
              COD_SALUD_MENTAL + 
              SEXO + 
              recod_estado_civil + 
              rangos_edad,
           family = binomial(link="logit"),
           data = base_igi_14)
summary(mod0b)
exp(coef(mod0b))

```

Los modelos con redes incluidos:

```{r reg_clusters,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}

id1 <- row.names(datos_sub1_14)
id2 <- row.names(datos_sub2_14)
id3 <- row.names(datos_sub3_14)

base_igi_14$cluster <- ifelse(row.names(base_igi_14) %in% id1, 1,
                              ifelse(row.names(base_igi_14) %in% id2, 2,
                                     ifelse(row.names(base_igi_14) %in% id3, 3, NA)))
base_igi_14 <- base_igi_14[is.na(base_igi_14$cluster)==F,]
base_igi_14_red1y3 <- base_igi_14[base_igi_14$cluster!=2,]


# mob1
mod1 <- glm(reincidencia ~ puntaje_total + factor(cluster),
           family = binomial(link="logit"),
           data = base_igi_14)
summary(mod1)
exp(coef(mod1))

# mob2
mod2 <- glm(reincidencia ~ puntaje_total + factor(cluster) + 
              COD_SALUD_MENTAL + 
              SEXO + 
              recod_estado_civil + 
              rangos_edad,
           family = binomial(link="logit"),
           data = base_igi_14)
summary(mod2)
exp(coef(mod2))


```

```{r pares_significativos,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
pares_enlaces <- list(
  c("HD1",   "HD5"   ),
  c("UTL23", "PAR25" ),
  c("PAR25", "PAR26" ),
  c("EDU10", "CAD28" ),
  c("PAR25", "CAD28" ),
  c("HD2",   "CAD29" ),
  c("EDU16", "CAD30" ),
  c("CAD28", "CAD30" ),
  c("HD5",   "CAD31" ),
  c("EDU11", "CAD31" ),
  c("CAD28", "CAD31" ),
  c("CAD29", "CAD31" ),
  c("CAD30", "CAD31" ),
  c("CAD30", "CAD34" ),
  c("CAD31", "CAD34" ),
  c("PRO36", "PAT42" ),
  c("HD5",   "PAT43" ),
  c("CAD31", "PAT43" ),
  c("PAT41", "PAT43" )
)



for (i in seq_along(pares_enlaces)) {
  var1 <- pares_enlaces[[i]][1]
  var2 <- pares_enlaces[[i]][2]
  
  # Nombre de la nueva variable
  new_var_name <- paste0("coact_", var1, "_", var2)
  
  # Crear la variable en base_igi_14
  # coactivación =  1  si (1,1)
  # activación-opuesta = -1 si (1,0) o (0,1)
  # inactivación =  0  si (0,0)
  base_igi_14[[new_var_name]] <- ifelse(
    base_igi_14[[var1]] == 1 & base_igi_14[[var2]] == 1, 
    1,0)
}

for (i in seq_along(pares_enlaces)) {
  var1 <- pares_enlaces[[i]][1]
  var2 <- pares_enlaces[[i]][2]
  
  # Nombre de la nueva variable
  new_var_name <- paste0("no_coact_", var1, "_", var2)
  
  # Crear la variable en base_igi_14
  # coactivación =  1  si (1,1)
  # activación-opuesta = -1 si (1,0) o (0,1)
  # inactivación =  0  si (0,0)
  base_igi_14[[new_var_name]] <- ifelse(
    base_igi_14[[var1]] == 1 & base_igi_14[[var2]] != 1, 
    1,
    ifelse(
          base_igi_14[[var1]] != 1 & base_igi_14[[var2]] == 1, 
    1,0))
}




# Creamos un vector con los nombres de las columnas generadas
nombres_coact <- sapply(pares_enlaces, function(par) {
  paste0("coact_", par[1], "_", par[2])
})

nombres_no_coact <- sapply(pares_enlaces, function(par) {
  paste0("no_coact_", par[1], "_", par[2])
})

# Para cada fila (individuo), contamos cuántas columnas tienen valor 1 o -1.
base_igi_14$indice_coactivacion_positiva <- rowSums(base_igi_14[, nombres_coact] == 1, na.rm = TRUE)
base_igi_14$indice_coactivacion_negativa <- rowSums(base_igi_14[, nombres_no_coact] == 1, na.rm = TRUE)

###############################################################################
# 4. Ajustar una regresión logística
###############################################################################
# Asumiendo que la variable de interés es "Reincidencia" (0/1), 
# y que "puntaje_total" es la suma de los 43 ítems o la variable que hayas definido.

# modelo logístico
modelo_log <- glm(
  reincidencia ~ puntaje_total + indice_coactivacion_positiva + indice_coactivacion_negativa +
    COD_SALUD_MENTAL + 
              SEXO + 
              recod_estado_civil + 
              rangos_edad + 
    cluster,
  family = binomial(link = "logit"),
  data = base_igi_14
)

print("Resumen del modelo glm(
  reincidencia ~ puntaje_total + indice_coactivacion_positiva + indice_coactivacion_negativa +
    COD_SALUD_MENTAL + 
              SEXO + 
              recod_estado_civil + 
              rangos_edad + 
    cluster,
  family = binomial(link = 'logit'),
  data = base_igi_14
)")

summary(modelo_log)

# Opcional: exp(coef(modelo_log)) para ver Odds Ratios
exp(coef(modelo_log))

###############
modelo_log_full <- glm(reincidencia ~ 
  puntaje_total + 
  factor(cluster) + 
    COD_SALUD_MENTAL + 
              SEXO + 
              recod_estado_civil + 
              rangos_edad + 
  coact_HD1_HD5 + coact_UTL23_PAR25 + coact_PAR25_PAR26 + 
  coact_EDU10_CAD28 + coact_PAR25_CAD28 + coact_HD2_CAD29 + 
  coact_EDU16_CAD30 + coact_CAD28_CAD30 + coact_HD5_CAD31 +
  coact_EDU11_CAD31 + coact_CAD28_CAD31 + coact_CAD29_CAD31 +
  coact_CAD30_CAD31 + coact_CAD30_CAD34 + coact_CAD31_CAD34 +
  coact_PRO36_PAT42 + coact_HD5_PAT43 + coact_CAD31_PAT43 + 
  coact_PAT41_PAT43 + 
    no_coact_HD1_HD5 + no_coact_UTL23_PAR25 + no_coact_PAR25_PAR26 + 
  no_coact_EDU10_CAD28 + no_coact_PAR25_CAD28 + no_coact_HD2_CAD29 + 
  no_coact_EDU16_CAD30 + no_coact_CAD28_CAD30 + no_coact_HD5_CAD31 +
  no_coact_EDU11_CAD31 + no_coact_CAD28_CAD31 + no_coact_CAD29_CAD31 +
  no_coact_CAD30_CAD31 + no_coact_CAD30_CAD34 + no_coact_CAD31_CAD34 +
  no_coact_PRO36_PAT42 + no_coact_HD5_PAT43 + no_coact_CAD31_PAT43 + 
  no_coact_PAT41_PAT43 ,
  family = binomial(link = "logit"),
  data = base_igi_14)

print("modelo_log_full <- glm(reincidencia ~ 
  puntaje_total + 
  factor(cluster) + 
    COD_SALUD_MENTAL + 
              SEXO + 
              recod_estado_civil + 
              rangos_edad + 
  coact_HD1_HD5 + coact_UTL23_PAR25 + coact_PAR25_PAR26 + 
  coact_EDU10_CAD28 + coact_PAR25_CAD28 + coact_HD2_CAD29 + 
  coact_EDU16_CAD30 + coact_CAD28_CAD30 + coact_HD5_CAD31 +
  coact_EDU11_CAD31 + coact_CAD28_CAD31 + coact_CAD29_CAD31 +
  coact_CAD30_CAD31 + coact_CAD30_CAD34 + coact_CAD31_CAD34 +
  coact_PRO36_PAT42 + coact_HD5_PAT43 + coact_CAD31_PAT43 + 
  coact_PAT41_PAT43 + 
    no_coact_HD1_HD5 + no_coact_UTL23_PAR25 + no_coact_PAR25_PAR26 + 
  no_coact_EDU10_CAD28 + no_coact_PAR25_CAD28 + no_coact_HD2_CAD29 + 
  no_coact_EDU16_CAD30 + no_coact_CAD28_CAD30 + no_coact_HD5_CAD31 +
  no_coact_EDU11_CAD31 + no_coact_CAD28_CAD31 + no_coact_CAD29_CAD31 +
  no_coact_CAD30_CAD31 + no_coact_CAD30_CAD34 + no_coact_CAD31_CAD34 +
  no_coact_PRO36_PAT42 + no_coact_HD5_PAT43 + no_coact_CAD31_PAT43 + 
  no_coact_PAT41_PAT43 ,
  family = binomial(link = 'logit'),
  data = base_igi_14)")
summary(modelo_log_full)

################################################################################
# Modelo con los 19 enlaces

library(glmnet)

formula_lasso <- reincidencia ~ 
  puntaje_total + 
  factor(cluster) + 
  coact_HD1_HD5 + coact_UTL23_PAR25 + coact_PAR25_PAR26 + 
  coact_EDU10_CAD28 + coact_PAR25_CAD28 + coact_HD2_CAD29 + 
  coact_EDU16_CAD30 + coact_CAD28_CAD30 + coact_HD5_CAD31 +
  coact_EDU11_CAD31 + coact_CAD28_CAD31 + coact_CAD29_CAD31 +
  coact_CAD30_CAD31 + coact_CAD30_CAD34 + coact_CAD31_CAD34 +
  coact_PRO36_PAT42 + coact_HD5_PAT43 + coact_CAD31_PAT43 + 
  coact_PAT41_PAT43 + 
  no_coact_HD1_HD5 + no_coact_UTL23_PAR25 + no_coact_PAR25_PAR26 + 
  no_coact_EDU10_CAD28 + no_coact_PAR25_CAD28 + no_coact_HD2_CAD29 + 
  no_coact_EDU16_CAD30 + no_coact_CAD28_CAD30 + no_coact_HD5_CAD31 +
  no_coact_EDU11_CAD31 + no_coact_CAD28_CAD31 + no_coact_CAD29_CAD31 +
  no_coact_CAD30_CAD31 + no_coact_CAD30_CAD34 + no_coact_CAD31_CAD34 +
  no_coact_PRO36_PAT42 + no_coact_HD5_PAT43 + no_coact_CAD31_PAT43 + 
  no_coact_PAT41_PAT43 

X <- model.matrix(formula_lasso, data = base_igi_14)[, -1]

# Variable respuesta (vector)
y <- base_igi_14$reincidencia  # as.numeric(0/1)

set.seed(123)  # Para reproducibilidad

cv_fit <- cv.glmnet(
  x = X,
  y = y,
  family = "binomial",  # Regresión logística
  alpha = 1,            # alpha=1 => LASSO
  # Por defecto, cv.glmnet usa 10-fold cross-validation
)

# cv_fit contiene la trayectoria de lambdas y los errores de validación.

###############################################################################
# 4. Seleccionar el lambda óptimo y revisar resultados
###############################################################################
# Se suelen usar:
#   - lambda.min: el valor de lambda que minimiza el error de validación
#   - lambda.1se: el valor de lambda más sencillo (mayor) que sigue estando 
#                 dentro de 1 std error del mínimo

lambda_optimo <- cv_fit$lambda.min
lambda_mas_simple <- cv_fit$lambda.1se

# Revisar coeficientes con lambda.min
coef_min <- coef(cv_fit, s = "lambda.min")

print("Resumen del modelo LASSO")
coef_min

# Revisar coeficientes con lambda.1se
coef_1se <- coef(cv_fit, s = "lambda.1se")
coef_1se

###############################################################################
# 5. Interpretación adicional
###############################################################################
# coef_min y coef_1se son objetos 'dgCMatrix' con los coeficientes 
# (incluyendo intercept) estimados para cada predictor.
# P.ej., para extraerlos en un data frame legible:

coef_table_min <- data.frame(
  predictor = rownames(coef_min),
  estimate  = as.numeric(coef_min)
)
coef_table_min

# Filtra estimados != 0
coef_nonzero_min <- subset(coef_table_min, estimate != 0)
coef_nonzero_min

# Este subset mostrará cuáles variables quedaron seleccionadas 
# por el LASSO al penalizar los demás coeficientes a 0.

###############################################################################
# (Opcional) Calcular AUC o performance
###############################################################################
# Predecir en la misma data (o en un set de test) y calcular la prob.
pred_prob <- predict(cv_fit, newx = X, s = "lambda.min", type = "response")

# Comparar con y para obtener AUC, etc.
library(pROC)
roc_obj <- roc(y, as.numeric(pred_prob))
auc(roc_obj)

```

# Enlaces que resultaron significativos al incluir el análisis de redes

```{r,  echo=FALSE, warning=FALSE, message=FALSE, include=TRUE}
pares_enlaces <- list(
  c("HD1",   "HD5"   ),
  c("UTL23", "PAR25" ),
  c("PAR25", "PAR26" ),
  c("EDU10", "CAD28" ),
  c("PAR25", "CAD28" ),
  c("HD2",   "CAD29" ),
  c("EDU16", "CAD30" ),
  c("CAD28", "CAD30" ),
  c("HD5",   "CAD31" ),
  c("EDU11", "CAD31" ),
  c("CAD28", "CAD31" ),
  c("CAD29", "CAD31" ),
  c("CAD30", "CAD31" ),
  c("CAD30", "CAD34" ),
  c("CAD31", "CAD34" ),
  c("PRO36", "PAT42" ),
  c("HD5",   "PAT43" ),
  c("CAD31", "PAT43" ),
  c("PAT41", "PAT43" )
)

for (i in seq_along(pares_enlaces)) {
  var1 <- pares_enlaces[[i]][1]
  var2 <- pares_enlaces[[i]][2]
  
  # Nombre de la nueva variable
  new_var_name <- paste0("coact_", var1, "_", var2)
  
  # Crear la variable en base_igi_14_red1y3
  # coactivación =  1  si (1,1)
  # activación-opuesta = -1 si (1,0) o (0,1)
  # inactivación =  0  si (0,0)
  base_igi_14_red1y3[[new_var_name]] <- ifelse(
    base_igi_14_red1y3[[var1]] == 1 & base_igi_14_red1y3[[var2]] == 1, 
    1,
    ifelse(
      base_igi_14_red1y3[[var1]] != base_igi_14_red1y3[[var2]], 
      -1, 
      0
    )
  )
}

# Creamos un vector con los nombres de las columnas generadas
nombres_coact <- sapply(pares_enlaces, function(par) {
  paste0("coact_", par[1], "_", par[2])
})

# Para cada fila (individuo), contamos cuántas columnas tienen valor 1 o -1.
base_igi_14_red1y3$indice_coactivacion_positiva <- rowSums(base_igi_14_red1y3[, nombres_coact] == 1, na.rm = TRUE)
base_igi_14_red1y3$indice_coactivacion_negativa <- rowSums(base_igi_14_red1y3[, nombres_coact] == -1, na.rm = TRUE)

###############################################################################
# 4. Ajustar una regresión logística
###############################################################################

# modelo logístico
modelo_log <- glm(
  reincidencia ~ puntaje_total + indice_coactivacion_positiva + indice_coactivacion_negativa +
    COD_SALUD_MENTAL + 
              SEXO + 
              recod_estado_civil + 
              rangos_edad + 
    cluster,
  family = binomial(link = "logit"),
  data = base_igi_14_red1y3
)

summary(modelo_log)

# Opcional: exp(coef(modelo_log)) para ver Odds Ratios
exp(coef(modelo_log))

modelo_log_full <- glm(reincidencia ~ 
  puntaje_total + 
  factor(cluster) + 
    COD_SALUD_MENTAL + 
              SEXO + 
              recod_estado_civil + 
              rangos_edad + 
  coact_HD1_HD5 + coact_UTL23_PAR25 + coact_PAR25_PAR26 + 
  coact_EDU10_CAD28 + coact_PAR25_CAD28 + coact_HD2_CAD29 + 
  coact_EDU16_CAD30 + coact_CAD28_CAD30 + coact_HD5_CAD31 +
  coact_EDU11_CAD31 + coact_CAD28_CAD31 + coact_CAD29_CAD31 +
  coact_CAD30_CAD31 + coact_CAD30_CAD34 + coact_CAD31_CAD34 +
  coact_PRO36_PAT42 + coact_HD5_PAT43 + coact_CAD31_PAT43 + 
  coact_PAT41_PAT43,
  family = binomial(link = "logit"),
  data = base_igi_14_red1y3)
summary(modelo_log_full)

################################################################################
# Modelo con los 19 enlaces

library(glmnet)

formula_lasso <- reincidencia ~ 
  puntaje_total + 
  factor(cluster) + 
  coact_HD1_HD5 + coact_UTL23_PAR25 + coact_PAR25_PAR26 + 
  coact_EDU10_CAD28 + coact_PAR25_CAD28 + coact_HD2_CAD29 + 
  coact_EDU16_CAD30 + coact_CAD28_CAD30 + coact_HD5_CAD31 +
  coact_EDU11_CAD31 + coact_CAD28_CAD31 + coact_CAD29_CAD31 +
  coact_CAD30_CAD31 + coact_CAD30_CAD34 + coact_CAD31_CAD34 +
  coact_PRO36_PAT42 + coact_HD5_PAT43 + coact_CAD31_PAT43 + 
  coact_PAT41_PAT43

X <- model.matrix(formula_lasso, data = base_igi_14_red1y3)[, -1]

# Variable respuesta (vector)
y <- base_igi_14_red1y3$reincidencia  # as.numeric(0/1)

set.seed(123)  # Para reproducibilidad

cv_fit <- cv.glmnet(
  x = X,
  y = y,
  family = "binomial",  # Regresión logística
  alpha = 1,            # alpha=1 => LASSO
  # Por defecto, cv.glmnet usa 10-fold cross-validation

)

# cv_fit contiene la trayectoria de lambdas y los errores de validación.

###############################################################################
# 4. Seleccionar el lambda óptimo y revisar resultados
###############################################################################
# Se suelen usar:
#   - lambda.min: el valor de lambda que minimiza el error de validación
#   - lambda.1se: el valor de lambda más sencillo (mayor) que sigue estando 
#                 dentro de 1 std error del mínimo

lambda_optimo <- cv_fit$lambda.min
lambda_mas_simple <- cv_fit$lambda.1se

# Revisar coeficientes con lambda.min
coef_min <- coef(cv_fit, s = "lambda.min")
coef_min

# Revisar coeficientes con lambda.1se
coef_1se <- coef(cv_fit, s = "lambda.1se")
coef_1se

###############################################################################
# 5. Interpretación adicional
###############################################################################
# coef_min y coef_1se son objetos 'dgCMatrix' con los coeficientes 
# (incluyendo intercept) estimados para cada predictor.
# P.ej., para extraerlos en un data frame legible:

coef_table_min <- data.frame(
  predictor = rownames(coef_min),
  estimate  = as.numeric(coef_min)
)
coef_table_min

# Filtra estimados != 0
coef_nonzero_min <- subset(coef_table_min, estimate != 0)
coef_nonzero_min

# Este subset te mostrará cuáles variables quedaron seleccionadas 
# por el LASSO al penalizar los demás coeficientes a 0.

###############################################################################
# (Opcional) Calcular AUC o performance
###############################################################################

pred_prob <- predict(cv_fit, newx = X, s = "lambda.min", type = "response")

# Comparar con y para obtener AUC, etc.
library(pROC)
roc_obj <- roc(y, as.numeric(pred_prob))
auc(roc_obj)

```
